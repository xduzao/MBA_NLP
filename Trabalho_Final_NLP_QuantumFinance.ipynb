{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Case QuantumFinance - Disciplina NLP - Classificador de chamados**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Aten√ß√£o:**\n",
        "- Leia com aten√ß√£o o descritivo do trabalho e as orienta√ß√µes do template.\n",
        "- O trabalho deve ser entregue respeitando a estrutura do arquivo de template em notebook \"Template_Trabalho_Final_NLP.ipynb\" e compactado no formato .zip. Apenas um arquivo no formato .ipynb deve ser entregue consolidando todo o trabalho.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Participantes (RM - NOME):***<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###**Crie um classificador de chamados aplicando t√©cnicas de PLN**\n",
        "---\n",
        "\n",
        "A **QuantumFinance** tem um canal de atendimento via chat e precisar classificar os assuntos dos atendimentos para melhorar as tratativas dos chamados dos clientes. O canal recebe textos abertos dos clientes relatando o problema e/ou d√∫vida e depois √© direcionado para alguma √°rea especialista no assunto para uma melhor tratativa.‚Äã\n",
        "\n",
        "1. Crie ao menos um modelo classificador de assuntos aplicando t√©cnicas de NLP (PLN), Vetoriza√ß√£o (n-grama + m√©trica) e modelo supervisionado, que consiga classificar atrav√©s de um texto o assunto conforme dispon√≠vel na base de dados [1] para treinamento e valida√ß√£o do seu modelo.‚Äã\n",
        "\n",
        "  O modelo precisar atingir um score na **m√©trica F1 Score superior a 75%**. Utilize o dataset [1] para treinar e testar o modelo, separe o dataset em duas amostras (75% para treinamento e 25% para teste com o randon_state igual a 42).‚Äã\n",
        "\n",
        "2. Utilizar ao menos uma aplica√ß√£o de modelos com Embeddings usando Word2Vec e/ou LLM¬¥s para criar o modelo classificador com os crit√©rios do item 1. N√£o √© necess√°rio implementar aplica√ß√µes usando servi√ßos de API da OpenAI ou outros por exemplo.\n",
        "\n",
        "Fique √† vontade para testar e explorar as t√©cnicas de pr√©-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decis√µes durante o desenvolvimento.‚Äã\n",
        "\n",
        "**Composi√ß√£o da nota:‚Äã**\n",
        "\n",
        "**50%** - Demonstra√ß√µes das aplica√ß√µes das t√©cnicas de PLN (regras, pr√©-processamentos, tratamentos, variedade de modelos aplicados, aplica√ß√µes de GenIA, organiza√ß√£o do pipeline, etc.)‚Äã\n",
        "\n",
        "**50%** - Baseado na performance (score) obtida com a amostra de teste no pipeline do modelo campe√£o (validar com  a M√©trica F1 Score). **Separar o pipeline completo do modelo campe√£o conforme template.‚Äã**\n",
        "\n",
        "O trabalho poder√° ser feito em grupo de 2 at√© 4 pessoas (mesmo grupo do Startup One) e trabalhos iguais ser√£o descontado nota e pass√≠vel de reprova√ß√£o.\n",
        "\n",
        "**[1] = ‚Äãhttps://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv**\n",
        "\n",
        "**[F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)** com average='weighted'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Setup Inicial e Carregamento dos Dados**\n",
        "\n",
        "### Importa√ß√£o de Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bibliotecas b√°sicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualiza√ß√£o\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "import spacy\n",
        "\n",
        "# Scikit-learn - Pr√©-processamento e Split\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# Scikit-learn - Modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Scikit-learn - M√©tricas\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Persist√™ncia\n",
        "import joblib\n",
        "import time\n",
        "\n",
        "# Configura√ß√µes de visualiza√ß√£o\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úì Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download de recursos necess√°rios do NLTK\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('rslp', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Verificar/instalar modelo spaCy portugu√™s\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "    print(\"‚úì Modelo spaCy pt_core_news_sm carregado!\")\n",
        "except:\n",
        "    print(\"‚ö† Modelo spaCy n√£o encontrado. Execute: python -m spacy download pt_core_news_sm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carregamento do Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CARREGANDO O DATA FRAME\n",
        "df = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', \n",
        "                 delimiter=';')\n",
        "\n",
        "# Fa√ßam o download do arquivo e utilizem localmente durante os testes\n",
        "print(f\"Dataset carregado: {df.shape[0]} registros e {df.shape[1]} colunas\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separa√ß√£o Treino/Teste (75%/25%)\n",
        "\n",
        "Conforme especificado no enunciado, utilizaremos **random_state=42** e split **estratificado** para manter a propor√ß√£o das classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separa√ß√£o estratificada dos dados\n",
        "X = df['descricao_reclamacao']\n",
        "y = df['categoria']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.25, \n",
        "    random_state=42, \n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Conjunto de Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Conjunto de Teste: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nDistribui√ß√£o de classes no treino:\")\n",
        "print(y_train.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **√Årea de Desenvolvimento e Valida√ß√µes**\n",
        "\n",
        "Fa√ßa aqui as demonstra√ß√µes das aplica√ß√µes das t√©cnicas de PLN (regras, pr√©-processamentos, tratamentos, variedade de modelos aplicados, organiza√ß√£o do pipeline, etc.)‚Äã\n",
        "\n",
        "Fique √† vontade para testar e explorar as t√©cnicas de pr√©-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decis√µes durante o desenvolvimento.‚Äã\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. An√°lise Explorat√≥ria dos Dados (EDA)**\n",
        "\n",
        "### **Justificativa:**\n",
        "\n",
        "A base cont√©m textos curtos (descri√ß√µes de reclama√ß√µes), com classes que precisam ser verificadas quanto ao equil√≠brio. √â essencial verificar vocabul√°rio, nulos e validar se h√° termos representativos por categoria. \n",
        "\n",
        "A an√°lise de **frequ√™ncia das classes**, **comprimento m√©dio** e **n-grams mais frequentes** confirma se bigramas ajudam a capturar contexto curto (ex: \"cart√£o bloqueado\", \"empr√©stimo negado\"). \n",
        "\n",
        "Detectar **palavras de dom√≠nio** que podem virar stopwords personalizadas (ex: \"reclama√ß√£o\", \"cliente\") refor√ßa a necessidade de vetoriza√ß√£o **TF-IDF com bigramas**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Verifica√ß√µes B√°sicas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verifica√ß√£o de valores nulos\n",
        "print(\"=== Valores Nulos ===\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nTotal de nulos: {df.isnull().sum().sum()}\")\n",
        "\n",
        "# Verifica√ß√£o de duplicados\n",
        "print(f\"\\n=== Duplicados ===\")\n",
        "print(f\"Registros duplicados: {df.duplicated().sum()}\")\n",
        "\n",
        "# Verifica√ß√£o de textos vazios\n",
        "print(f\"\\n=== Textos Vazios ===\")\n",
        "textos_vazios = df['descricao_reclamacao'].str.strip().str.len() == 0\n",
        "print(f\"Textos vazios: {textos_vazios.sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Distribui√ß√£o de Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contagem e percentual de cada categoria\n",
        "print(\"=== Distribui√ß√£o de Categorias ===\")\n",
        "categoria_counts = df['categoria'].value_counts()\n",
        "categoria_percent = df['categoria'].value_counts(normalize=True) * 100\n",
        "\n",
        "distribuicao = pd.DataFrame({\n",
        "    'Quantidade': categoria_counts,\n",
        "    'Percentual (%)': categoria_percent.round(2)\n",
        "})\n",
        "print(distribuicao)\n",
        "\n",
        "# Visualiza√ß√£o\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Gr√°fico de barras\n",
        "sns.countplot(data=df, y='categoria', order=categoria_counts.index, ax=axes[0])\n",
        "axes[0].set_title('Distribui√ß√£o de Categorias', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Quantidade')\n",
        "axes[0].set_ylabel('Categoria')\n",
        "\n",
        "# Gr√°fico de pizza\n",
        "axes[1].pie(categoria_counts, labels=categoria_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "axes[1].set_title('Propor√ß√£o de Categorias', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì An√°lise: As classes apresentam distribui√ß√£o relativamente balanceada, o que √© favor√°vel para o treinamento.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 An√°lise de Comprimento dos Textos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lise de comprimento em caracteres e palavras\n",
        "df['num_caracteres'] = df['descricao_reclamacao'].str.len()\n",
        "df['num_palavras'] = df['descricao_reclamacao'].str.split().str.len()\n",
        "\n",
        "print(\"=== Estat√≠sticas de Comprimento dos Textos ===\")\n",
        "print(\"\\nCaracteres:\")\n",
        "print(df['num_caracteres'].describe())\n",
        "print(\"\\nPalavras:\")\n",
        "print(df['num_palavras'].describe())\n",
        "\n",
        "# Visualiza√ß√£o\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Histograma de caracteres\n",
        "axes[0].hist(df['num_caracteres'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title('Distribui√ß√£o do Comprimento em Caracteres', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('N√∫mero de Caracteres')\n",
        "axes[0].set_ylabel('Frequ√™ncia')\n",
        "axes[0].axvline(df['num_caracteres'].mean(), color='red', linestyle='--', label=f'M√©dia: {df[\"num_caracteres\"].mean():.0f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# Histograma de palavras\n",
        "axes[1].hist(df['num_palavras'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[1].set_title('Distribui√ß√£o do Comprimento em Palavras', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('N√∫mero de Palavras')\n",
        "axes[1].set_ylabel('Frequ√™ncia')\n",
        "axes[1].axvline(df['num_palavras'].mean(), color='red', linestyle='--', label=f'M√©dia: {df[\"num_palavras\"].mean():.0f}')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì An√°lise: Textos s√£o relativamente curtos (m√©dia ~30-40 palavras), confirmando a necessidade de capturar contexto com bigramas.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 An√°lise de N-gramas Frequentes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fun√ß√£o para extrair n-gramas mais frequentes\n",
        "def get_top_ngrams(corpus, n=1, top=20, use_stopwords=False):\n",
        "    \"\"\"\n",
        "    Extrai os n-gramas mais frequentes do corpus\n",
        "    \n",
        "    Par√¢metros:\n",
        "    - corpus: lista de textos\n",
        "    - n: tamanho do n-grama (1=unigrama, 2=bigrama)\n",
        "    - top: quantidade de n-gramas a retornar\n",
        "    - use_stopwords: se True, remove stopwords\n",
        "    \"\"\"\n",
        "    stop_words = stopwords.words('portuguese') if use_stopwords else None\n",
        "    \n",
        "    vec = CountVectorizer(\n",
        "        ngram_range=(n, n),\n",
        "        max_features=top,\n",
        "        stop_words=stop_words,\n",
        "        lowercase=True\n",
        "    ).fit(corpus)\n",
        "    \n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    return pd.DataFrame(words_freq, columns=['ngrama', 'frequencia'])\n",
        "\n",
        "# Extrair unigramas e bigramas\n",
        "print(\"=== Top 20 Unigramas (SEM remo√ß√£o de stopwords) ===\")\n",
        "top_unigrams = get_top_ngrams(df['descricao_reclamacao'], n=1, top=20, use_stopwords=False)\n",
        "print(top_unigrams)\n",
        "\n",
        "print(\"\\n=== Top 20 Unigramas (COM remo√ß√£o de stopwords) ===\")\n",
        "top_unigrams_clean = get_top_ngrams(df['descricao_reclamacao'], n=1, top=20, use_stopwords=True)\n",
        "print(top_unigrams_clean)\n",
        "\n",
        "print(\"\\n=== Top 20 Bigramas (COM remo√ß√£o de stopwords) ===\")\n",
        "top_bigrams = get_top_ngrams(df['descricao_reclamacao'], n=2, top=20, use_stopwords=True)\n",
        "print(top_bigrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o dos n-gramas mais frequentes\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Unigramas\n",
        "axes[0].barh(top_unigrams_clean['ngrama'][:15][::-1], top_unigrams_clean['frequencia'][:15][::-1])\n",
        "axes[0].set_title('Top 15 Unigramas (sem stopwords)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Frequ√™ncia')\n",
        "\n",
        "# Bigramas\n",
        "axes[1].barh(top_bigrams['ngrama'][:15][::-1], top_bigrams['frequencia'][:15][::-1], color='orange')\n",
        "axes[1].set_title('Top 15 Bigramas (sem stopwords)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Frequ√™ncia')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Decis√£o: Bigramas capturam contextos importantes do dom√≠nio financeiro (ex: 'conta corrente', 'cart√£o cr√©dito').\")\n",
        "print(\"  Utilizaremos ngram_range=(1,2) nos experimentos com TF-IDF.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Nuvem de Palavras por Categoria\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nuvem de palavras para cada categoria (apenas ilustrativo)\n",
        "categorias = df['categoria'].unique()\n",
        "stop_words_pt = set(stopwords.words('portuguese'))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, categoria in enumerate(categorias):\n",
        "    texto = ' '.join(df[df['categoria'] == categoria]['descricao_reclamacao'])\n",
        "    \n",
        "    wordcloud = WordCloud(\n",
        "        width=800, \n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        stopwords=stop_words_pt,\n",
        "        max_words=50,\n",
        "        colormap='viridis'\n",
        "    ).generate(texto)\n",
        "    \n",
        "    axes[idx].imshow(wordcloud, interpolation='bilinear')\n",
        "    axes[idx].set_title(categoria, fontsize=12, fontweight='bold')\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "# Remover subplot extra se houver\n",
        "if len(categorias) < 6:\n",
        "    for idx in range(len(categorias), 6):\n",
        "        fig.delaxes(axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úì As nuvens de palavras evidenciam termos caracter√≠sticos de cada categoria.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Pr√©-processamento de Texto**\n",
        "\n",
        "### **Justificativa:**\n",
        "\n",
        "Os textos s√£o em portugu√™s e provavelmente cont√™m ru√≠do (acentos, mai√∫sculas, stopwords comuns). O curso enfatizou **normaliza√ß√£o textual cl√°ssica** para modelos tradicionais.\n",
        "\n",
        "**Etapas mantidas:**\n",
        "- **Convers√£o para lowercase**: padroniza√ß√£o\n",
        "- **Remo√ß√£o de pontua√ß√£o e n√∫meros**: reduzir ru√≠do irrelevante\n",
        "- **Stopwords pt-BR (NLTK)**: remover termos gen√©ricos + customiza√ß√£o para dom√≠nio de atendimento\n",
        "- **Lematiza√ß√£o (spaCy pt)**: focando verbos e substantivos, preservando significado sem perder coer√™ncia\n",
        "\n",
        "**Por que N√ÉO usar stemiza√ß√£o aqui:**\n",
        "\n",
        "O dataset cont√©m categorias pr√≥ximas semanticamente (ex: \"Cart√£o de cr√©dito\" vs \"Servi√ßos de conta banc√°ria\"). Preservar o sentido exato das palavras √© mais importante do que radicaliz√°-las (como o stemmer faz). A lematiza√ß√£o mant√©m a forma linguisticamente correta.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Fun√ß√µes de Limpeza e Pr√©-processamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar stopwords e preparar modelo spaCy\n",
        "stop_words_pt = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Adicionar stopwords customizadas do dom√≠nio (baseado na EDA)\n",
        "custom_stopwords = {'cliente', 'favor', 'gostaria', 'solicito', 'pe√ßo', 'preciso'}\n",
        "stop_words_pt.update(custom_stopwords)\n",
        "\n",
        "# Carregar modelo spaCy\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "    print(\"‚úì Modelo spaCy carregado com sucesso!\")\n",
        "except:\n",
        "    print(\"‚ö† Execute: python -m spacy download pt_core_news_sm\")\n",
        "    nlp = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Limpeza b√°sica de texto:\n",
        "    - Lowercase\n",
        "    - Remo√ß√£o de n√∫meros\n",
        "    - Remo√ß√£o de pontua√ß√£o\n",
        "    - Remo√ß√£o de espa√ßos extras\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    \n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remover n√∫meros\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # Remover pontua√ß√£o\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    \n",
        "    # Remover espa√ßos extras\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "def lemmatize_text(text, keep_pos=['NOUN', 'VERB', 'ADJ']):\n",
        "    \"\"\"\n",
        "    Lematiza√ß√£o usando spaCy, mantendo apenas substantivos, verbos e adjetivos\n",
        "    \"\"\"\n",
        "    if nlp is None or not text:\n",
        "        return text\n",
        "    \n",
        "    doc = nlp(text)\n",
        "    lemmatized = [token.lemma_ for token in doc if token.pos_ in keep_pos and token.lemma_ not in stop_words_pt]\n",
        "    \n",
        "    return ' '.join(lemmatized)\n",
        "\n",
        "def preprocess_text(text, use_lemmatization=True):\n",
        "    \"\"\"\n",
        "    Pipeline completo de pr√©-processamento\n",
        "    \"\"\"\n",
        "    # Limpeza b√°sica\n",
        "    text = clean_text(text)\n",
        "    \n",
        "    # Remo√ß√£o de stopwords (se n√£o usar lematiza√ß√£o)\n",
        "    if not use_lemmatization:\n",
        "        tokens = text.split()\n",
        "        tokens = [word for word in tokens if word not in stop_words_pt and len(word) > 2]\n",
        "        text = ' '.join(tokens)\n",
        "    else:\n",
        "        # Lematiza√ß√£o (j√° remove stopwords)\n",
        "        text = lemmatize_text(text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Teste da fun√ß√£o\n",
        "texto_exemplo = \"Eu gostaria de solicitar o desbloqueio do meu cart√£o de cr√©dito que foi bloqueado ontem!\"\n",
        "print(\"Texto original:\")\n",
        "print(texto_exemplo)\n",
        "print(\"\\nTexto ap√≥s limpeza:\")\n",
        "print(clean_text(texto_exemplo))\n",
        "print(\"\\nTexto ap√≥s pr√©-processamento completo (com lematiza√ß√£o):\")\n",
        "print(preprocess_text(texto_exemplo))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Classe Transformadora Personalizada para Pipeline sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformador personalizado para pr√©-processamento de texto\n",
        "    Compat√≠vel com Pipeline do scikit-learn\n",
        "    \"\"\"\n",
        "    def __init__(self, use_lemmatization=True):\n",
        "        self.use_lemmatization = use_lemmatization\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        return X.apply(lambda text: preprocess_text(text, self.use_lemmatization))\n",
        "\n",
        "# Teste do transformador\n",
        "print(\"=== Teste do Transformador Personalizado ===\")\n",
        "preprocessor = TextPreprocessor(use_lemmatization=True)\n",
        "X_train_sample = X_train.head(3)\n",
        "X_train_processed = preprocessor.transform(X_train_sample)\n",
        "\n",
        "for original, processed in zip(X_train_sample, X_train_processed):\n",
        "    print(f\"\\nOriginal: {original[:100]}...\")\n",
        "    print(f\"Processado: {processed[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Compara√ß√£o: Stemiza√ß√£o vs Lematiza√ß√£o (Experimento Pontual)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compara√ß√£o entre stemiza√ß√£o e lematiza√ß√£o\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "def stem_text(text):\n",
        "    \"\"\"Aplica stemiza√ß√£o RSLP\"\"\"\n",
        "    tokens = clean_text(text).split()\n",
        "    stemmed = [stemmer.stem(word) for word in tokens if word not in stop_words_pt and len(word) > 2]\n",
        "    return ' '.join(stemmed)\n",
        "\n",
        "# Exemplo comparativo\n",
        "texto_teste = \"Os clientes solicitaram o desbloqueio dos cart√µes de cr√©dito que foram bloqueados.\"\n",
        "print(\"=== Compara√ß√£o Stemiza√ß√£o vs Lematiza√ß√£o ===\")\n",
        "print(f\"\\nTexto original:\\n{texto_teste}\")\n",
        "print(f\"\\nCom Stemiza√ß√£o (RSLP):\\n{stem_text(texto_teste)}\")\n",
        "print(f\"\\nCom Lematiza√ß√£o (spaCy):\\n{preprocess_text(texto_teste)}\")\n",
        "\n",
        "print(\"\\n‚úì Decis√£o: A lematiza√ß√£o preserva melhor o sentido das palavras, sendo mais adequada para este dom√≠nio.\")\n",
        "print(\"  Stemiza√ß√£o pode ser √∫til para reduzir ainda mais o vocabul√°rio, mas pode perder nuances importantes.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. Experimentos com Modelos Supervisionados**\n",
        "\n",
        "### **Justificativa Geral:**\n",
        "\n",
        "Nas aulas, foram apresentadas tr√™s estrat√©gias principais: **n-gramas + m√©tricas (Count/TF-IDF)** e **Embeddings**.\n",
        "\n",
        "Com frases curtas e vocabul√°rio de dom√≠nio financeiro, **TF-IDF bigramado** tende a ser muito eficaz. J√° **embeddings** permitem capturar sinon√≠mia e contexto (\"empr√©stimo negado\" ‚âà \"financiamento recusado\").\n",
        "\n",
        "**Modelos escolhidos** (todos vistos na disciplina):\n",
        "- **Regress√£o Log√≠stica (One-Vs-Rest)**: baseline forte e interpret√°vel\n",
        "- **Linear SVM**: robusta em dados textuais esparsos (alta dimensionalidade)\n",
        "- **Sentence Embeddings + Regress√£o Log√≠stica**: usa embeddings como entrada; simples e eficiente, sem fine-tuning\n",
        "\n",
        "Os dados s√£o de **alta dimensionalidade e dispers√£o** (vetores TF-IDF), situa√ß√£o em que **modelos lineares se destacam** (abordado em aula).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Experimento 1: TF-IDF + Regress√£o Log√≠stica**\n",
        "\n",
        "**Justificativa da Vetoriza√ß√£o:**\n",
        "- **TF-IDF (1-2 gram)**: captura termos curtos e combina frequ√™ncia local (TF) com import√¢ncia global (IDF)\n",
        "- **ngram_range=(1,2)**: unigramas + bigramas capturam express√µes do dom√≠nio\n",
        "- **sublinear_tf**: aplica log(TF) para suavizar impacto de termos muito frequentes\n",
        "- **min_df**: filtra termos que aparecem em poucos documentos (ru√≠do)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENTO 1: TF-IDF + REGRESS√ÉO LOG√çSTICA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Pr√©-processar os textos (aplicar lematiza√ß√£o)\n",
        "print(\"\\n[1/5] Pr√©-processando textos...\")\n",
        "X_train_processed = X_train.apply(lambda text: preprocess_text(text, use_lemmatization=True))\n",
        "X_test_processed = X_test.apply(lambda text: preprocess_text(text, use_lemmatization=True))\n",
        "print(f\"‚úì Processados {len(X_train_processed)} textos de treino e {len(X_test_processed)} de teste\")\n",
        "\n",
        "# Definir o pipeline\n",
        "print(\"\\n[2/5] Configurando pipeline e Grid Search...\")\n",
        "pipeline_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# Grid de hiperpar√¢metros\n",
        "param_grid_lr = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__sublinear_tf': [True, False],\n",
        "    'tfidf__min_df': [1, 2, 3],\n",
        "    'clf__C': [0.5, 1, 2, 4]\n",
        "}\n",
        "\n",
        "# GridSearchCV com 5-fold estratificado\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search_lr = GridSearchCV(\n",
        "    pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=cv,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "print(\"\\n[3/5] Treinando modelo com GridSearchCV (5-fold)...\")\n",
        "start_time = time.time()\n",
        "grid_search_lr.fit(X_train_processed, y_train)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "print(f\"‚úì Treinamento conclu√≠do em {train_time:.2f} segundos\")\n",
        "\n",
        "# Melhores hiperpar√¢metros\n",
        "print(\"\\n[4/5] Melhores hiperpar√¢metros encontrados:\")\n",
        "for param, value in grid_search_lr.best_params_.items():\n",
        "    print(f\"  - {param}: {value}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "print(\"\\n[5/5] Avalia√ß√£o no conjunto de teste...\")\n",
        "y_pred_lr = grid_search_lr.predict(X_test_processed)\n",
        "f1_test_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "accuracy_test_lr = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"\\nResultados no Teste:\")\n",
        "print(f\"  - F1-Score (weighted): {f1_test_lr:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_test_lr:.4f}\")\n",
        "print(f\"  - Tempo de treinamento: {train_time:.2f}s\")\n",
        "\n",
        "# Armazenar resultados\n",
        "results_exp1 = {\n",
        "    'model': 'TF-IDF + Regress√£o Log√≠stica',\n",
        "    'best_params': grid_search_lr.best_params_,\n",
        "    'f1_cv': grid_search_lr.best_score_,\n",
        "    'f1_test': f1_test_lr,\n",
        "    'accuracy_test': accuracy_test_lr,\n",
        "    'train_time': train_time,\n",
        "    'grid_search': grid_search_lr\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relat√≥rio de classifica√ß√£o detalhado\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RELAT√ìRIO DE CLASSIFICA√á√ÉO - EXPERIMENTO 1\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Matriz de confus√£o\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test, y_pred_lr)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=grid_search_lr.classes_, \n",
        "            yticklabels=grid_search_lr.classes_,\n",
        "            ax=ax)\n",
        "ax.set_title('Matriz de Confus√£o - TF-IDF + Regress√£o Log√≠stica', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Classe Real')\n",
        "ax.set_xlabel('Classe Predita')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lise das features mais importantes por classe\n",
        "print(\"\\n=== Features mais importantes por classe (Top 10) ===\\n\")\n",
        "\n",
        "# Obter o vetorizador e o classificador do melhor modelo\n",
        "best_model_lr = grid_search_lr.best_estimator_\n",
        "vectorizer = best_model_lr.named_steps['tfidf']\n",
        "classifier = best_model_lr.named_steps['clf']\n",
        "\n",
        "# Obter nomes das features\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Para cada classe, mostrar as features com maiores coeficientes\n",
        "for idx, classe in enumerate(classifier.classes_):\n",
        "    coefs = classifier.coef_[idx]\n",
        "    top_indices = np.argsort(coefs)[-10:][::-1]\n",
        "    top_features = [feature_names[i] for i in top_indices]\n",
        "    top_coefs = [coefs[i] for i in top_indices]\n",
        "    \n",
        "    print(f\"{classe}:\")\n",
        "    for feature, coef in zip(top_features, top_coefs):\n",
        "        print(f\"  {feature}: {coef:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Experimento 2: TF-IDF + Linear SVM**\n",
        "\n",
        "**Justificativa do Modelo:**\n",
        "- **LinearSVC** √© especialmente eficiente com dados de alta dimensionalidade (vetores TF-IDF)\n",
        "- Busca maximizar a margem entre classes, sendo robusto para textos esparsos\n",
        "- Compararemos com Regress√£o Log√≠stica para identificar qual captura melhor os padr√µes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENTO 2: TF-IDF + LINEAR SVM\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Pipeline (textos j√° foram pr√©-processados no Exp. 1)\n",
        "print(\"\\n[1/4] Configurando pipeline e Grid Search...\")\n",
        "pipeline_svm = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LinearSVC(max_iter=2000, random_state=42))\n",
        "])\n",
        "\n",
        "# Grid de hiperpar√¢metros\n",
        "param_grid_svm = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__sublinear_tf': [True, False],\n",
        "    'tfidf__min_df': [1, 2, 3],\n",
        "    'clf__C': [0.5, 1, 2, 4],\n",
        "    'clf__loss': ['hinge', 'squared_hinge']\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search_svm = GridSearchCV(\n",
        "    pipeline_svm,\n",
        "    param_grid_svm,\n",
        "    cv=cv,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "print(\"\\n[2/4] Treinando modelo com GridSearchCV (5-fold)...\")\n",
        "start_time = time.time()\n",
        "grid_search_svm.fit(X_train_processed, y_train)\n",
        "train_time_svm = time.time() - start_time\n",
        "\n",
        "print(f\"‚úì Treinamento conclu√≠do em {train_time_svm:.2f} segundos\")\n",
        "\n",
        "# Melhores hiperpar√¢metros\n",
        "print(\"\\n[3/4] Melhores hiperpar√¢metros encontrados:\")\n",
        "for param, value in grid_search_svm.best_params_.items():\n",
        "    print(f\"  - {param}: {value}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "print(\"\\n[4/4] Avalia√ß√£o no conjunto de teste...\")\n",
        "y_pred_svm = grid_search_svm.predict(X_test_processed)\n",
        "f1_test_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "accuracy_test_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"\\nResultados no Teste:\")\n",
        "print(f\"  - F1-Score (weighted): {f1_test_svm:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_test_svm:.4f}\")\n",
        "print(f\"  - Tempo de treinamento: {train_time_svm:.2f}s\")\n",
        "\n",
        "# Armazenar resultados\n",
        "results_exp2 = {\n",
        "    'model': 'TF-IDF + Linear SVM',\n",
        "    'best_params': grid_search_svm.best_params_,\n",
        "    'f1_cv': grid_search_svm.best_score_,\n",
        "    'f1_test': f1_test_svm,\n",
        "    'accuracy_test': accuracy_test_svm,\n",
        "    'train_time': train_time_svm,\n",
        "    'grid_search': grid_search_svm\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relat√≥rio de classifica√ß√£o\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RELAT√ìRIO DE CLASSIFICA√á√ÉO - EXPERIMENTO 2\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Matriz de confus√£o\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test, y_pred_svm)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
        "            xticklabels=grid_search_svm.classes_, \n",
        "            yticklabels=grid_search_svm.classes_,\n",
        "            ax=ax)\n",
        "ax.set_title('Matriz de Confus√£o - TF-IDF + Linear SVM', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Classe Real')\n",
        "ax.set_xlabel('Classe Predita')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Experimento 3: Sentence Embedding (Transformer) + Regress√£o Log√≠stica**\n",
        "\n",
        "**Justificativa da Vetoriza√ß√£o:**\n",
        "- **Sentence Embeddings**: extrai vetor denso representando sem√¢ntica completa da frase\n",
        "- Utiliza **Transformer multil√≠ngue** (modelo leve pr√©-treinado)\n",
        "- **Sem fine-tuning**: apenas extra√ß√£o de features, conforme visto em aula\n",
        "- Captura sinon√≠mia e contexto sem√¢ntico que TF-IDF n√£o consegue\n",
        "\n",
        "**Modelo:** Mantemos Regress√£o Log√≠stica pela simplicidade e boa performance com embeddings densos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENTO 3: SENTENCE EMBEDDING + REGRESS√ÉO LOG√çSTICA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Carregar modelo de Sentence Transformer\n",
        "print(\"\\n[1/5] Carregando modelo de embeddings...\")\n",
        "print(\"  Modelo: paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "print(\"‚úì Modelo carregado com sucesso!\")\n",
        "\n",
        "# Gerar embeddings (usando textos originais, n√£o pr√©-processados)\n",
        "# Transformers j√° lidam bem com o texto bruto\n",
        "print(\"\\n[2/5] Gerando embeddings para conjunto de treino...\")\n",
        "start_emb = time.time()\n",
        "X_train_embeddings = embedding_model.encode(X_train.tolist(), show_progress_bar=True)\n",
        "print(f\"‚úì Embeddings de treino gerados em {time.time() - start_emb:.2f}s\")\n",
        "print(f\"  Shape: {X_train_embeddings.shape}\")\n",
        "\n",
        "print(\"\\n[3/5] Gerando embeddings para conjunto de teste...\")\n",
        "X_test_embeddings = embedding_model.encode(X_test.tolist(), show_progress_bar=True)\n",
        "print(f\"‚úì Embeddings de teste gerados\")\n",
        "print(f\"  Shape: {X_test_embeddings.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinar Regress√£o Log√≠stica com GridSearch\n",
        "print(\"\\n[4/5] Treinando Regress√£o Log√≠stica com embeddings...\")\n",
        "\n",
        "param_grid_emb = {\n",
        "    'C': [0.5, 1, 2, 4],\n",
        "    'max_iter': [1000]\n",
        "}\n",
        "\n",
        "lr_emb = LogisticRegression(random_state=42)\n",
        "grid_search_emb = GridSearchCV(\n",
        "    lr_emb,\n",
        "    param_grid_emb,\n",
        "    cv=cv,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "grid_search_emb.fit(X_train_embeddings, y_train)\n",
        "train_time_emb = time.time() - start_time\n",
        "\n",
        "print(f\"‚úì Treinamento conclu√≠do em {train_time_emb:.2f} segundos\")\n",
        "\n",
        "# Melhores hiperpar√¢metros\n",
        "print(\"\\nMelhores hiperpar√¢metros:\")\n",
        "for param, value in grid_search_emb.best_params_.items():\n",
        "    print(f\"  - {param}: {value}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "print(\"\\n[5/5] Avalia√ß√£o no conjunto de teste...\")\n",
        "y_pred_emb = grid_search_emb.predict(X_test_embeddings)\n",
        "f1_test_emb = f1_score(y_test, y_pred_emb, average='weighted')\n",
        "accuracy_test_emb = accuracy_score(y_test, y_pred_emb)\n",
        "\n",
        "print(f\"\\nResultados no Teste:\")\n",
        "print(f\"  - F1-Score (weighted): {f1_test_emb:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_test_emb:.4f}\")\n",
        "print(f\"  - Tempo de treinamento: {train_time_emb:.2f}s\")\n",
        "\n",
        "# Armazenar resultados\n",
        "results_exp3 = {\n",
        "    'model': 'Sentence Embedding + Regress√£o Log√≠stica',\n",
        "    'best_params': grid_search_emb.best_params_,\n",
        "    'f1_cv': grid_search_emb.best_score_,\n",
        "    'f1_test': f1_test_emb,\n",
        "    'accuracy_test': accuracy_test_emb,\n",
        "    'train_time': train_time_emb,\n",
        "    'grid_search': grid_search_emb,\n",
        "    'embedding_model': embedding_model\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relat√≥rio de classifica√ß√£o\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RELAT√ìRIO DE CLASSIFICA√á√ÉO - EXPERIMENTO 3\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, y_pred_emb))\n",
        "\n",
        "# Matriz de confus√£o\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test, y_pred_emb)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', \n",
        "            xticklabels=grid_search_emb.classes_, \n",
        "            yticklabels=grid_search_emb.classes_,\n",
        "            ax=ax)\n",
        "ax.set_title('Matriz de Confus√£o - Sentence Embedding + Regress√£o Log√≠stica', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Classe Real')\n",
        "ax.set_xlabel('Classe Predita')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5. Compara√ß√£o dos Modelos e Sele√ß√£o do Campe√£o**\n",
        "\n",
        "### **Justificativa:**\n",
        "\n",
        "As classes s√£o pr√≥ximas e o objetivo √© maximizar equil√≠brio entre precision e recall ‚Äî logo, **F1-macro √© a m√©trica certa** (confirmado no enunciado).\n",
        "\n",
        "Uso de **5-fold CV no treino** garante robustez antes do teste final.\n",
        "\n",
        "**Crit√©rio de sele√ß√£o:**\n",
        "- Melhor F1-Score (weighted) no teste ‚â• 0.75\n",
        "- Em caso de empate: escolher modelo mais simples e leve (produ√ß√£o)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"COMPARA√á√ÉO DOS MODELOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Consolidar resultados em DataFrame\n",
        "comparacao = pd.DataFrame([\n",
        "    {\n",
        "        'Modelo': results_exp1['model'],\n",
        "        'F1-Score CV (m√©dia)': f\"{results_exp1['f1_cv']:.4f}\",\n",
        "        'F1-Score Teste': f\"{results_exp1['f1_test']:.4f}\",\n",
        "        'Accuracy Teste': f\"{results_exp1['accuracy_test']:.4f}\",\n",
        "        'Tempo Treino (s)': f\"{results_exp1['train_time']:.2f}\"\n",
        "    },\n",
        "    {\n",
        "        'Modelo': results_exp2['model'],\n",
        "        'F1-Score CV (m√©dia)': f\"{results_exp2['f1_cv']:.4f}\",\n",
        "        'F1-Score Teste': f\"{results_exp2['f1_test']:.4f}\",\n",
        "        'Accuracy Teste': f\"{results_exp2['accuracy_test']:.4f}\",\n",
        "        'Tempo Treino (s)': f\"{results_exp2['train_time']:.2f}\"\n",
        "    },\n",
        "    {\n",
        "        'Modelo': results_exp3['model'],\n",
        "        'F1-Score CV (m√©dia)': f\"{results_exp3['f1_cv']:.4f}\",\n",
        "        'F1-Score Teste': f\"{results_exp3['f1_test']:.4f}\",\n",
        "        'Accuracy Teste': f\"{results_exp3['accuracy_test']:.4f}\",\n",
        "        'Tempo Treino (s)': f\"{results_exp3['train_time']:.2f}\"\n",
        "    }\n",
        "])\n",
        "\n",
        "print(\"\\n\", comparacao.to_string(index=False))\n",
        "\n",
        "# Determinar o campe√£o\n",
        "f1_scores = [results_exp1['f1_test'], results_exp2['f1_test'], results_exp3['f1_test']]\n",
        "best_idx = np.argmax(f1_scores)\n",
        "experiments = [results_exp1, results_exp2, results_exp3]\n",
        "champion = experiments[best_idx]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üèÜ MODELO CAMPE√ÉO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nModelo: {champion['model']}\")\n",
        "print(f\"F1-Score (Teste): {champion['f1_test']:.4f}\")\n",
        "print(f\"Accuracy (Teste): {champion['accuracy_test']:.4f}\")\n",
        "print(f\"F1-Score (CV): {champion['f1_cv']:.4f}\")\n",
        "\n",
        "if champion['f1_test'] >= 0.75:\n",
        "    print(f\"\\n‚úì Meta atingida! F1-Score > 0.75\")\n",
        "else:\n",
        "    print(f\"\\n‚ö† Meta n√£o atingida. F1-Score < 0.75\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o comparativa\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# F1-Score Teste\n",
        "modelos = ['TF-IDF +\\nLogReg', 'TF-IDF +\\nSVM', 'Embedding +\\nLogReg']\n",
        "f1_cv_scores = [results_exp1['f1_cv'], results_exp2['f1_cv'], results_exp3['f1_cv']]\n",
        "f1_test_scores = [results_exp1['f1_test'], results_exp2['f1_test'], results_exp3['f1_test']]\n",
        "\n",
        "x_pos = np.arange(len(modelos))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x_pos - width/2, f1_cv_scores, width, label='F1-CV', alpha=0.8)\n",
        "axes[0].bar(x_pos + width/2, f1_test_scores, width, label='F1-Teste', alpha=0.8)\n",
        "axes[0].axhline(y=0.75, color='r', linestyle='--', label='Meta (0.75)')\n",
        "axes[0].set_ylabel('F1-Score')\n",
        "axes[0].set_title('Compara√ß√£o de F1-Score: CV vs Teste', fontweight='bold')\n",
        "axes[0].set_xticks(x_pos)\n",
        "axes[0].set_xticklabels(modelos)\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Tempo de Treinamento\n",
        "tempos = [results_exp1['train_time'], results_exp2['train_time'], results_exp3['train_time']]\n",
        "axes[1].bar(modelos, tempos, color=['skyblue', 'lightgreen', 'orange'], alpha=0.8)\n",
        "axes[1].set_ylabel('Tempo (segundos)')\n",
        "axes[1].set_title('Tempo de Treinamento', fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **VALIDA√á√ÉO DO PROFESSOR**\n",
        "\n",
        "Consolidar apenas os scripts do seu **modelo campe√£o**, desde o carregamento do dataframe, separa√ß√£o das amostras, tratamentos utilizados (fun√ß√µes, limpezas, etc.), cria√ß√£o dos objetos de vetoriza√ß√£o dos textos e modelo treinado e outras implementa√ß√µes utilizadas no processo de desenvolvimento do modelo.\n",
        "\n",
        "O modelo precisar atingir um score na m√©trica F1 Score superior a 75%.\n",
        "\n",
        "**Aten√ß√£o:**\n",
        "- **Implemente aqui apenas os scripts que fazem parte do modelo campe√£o.**\n",
        "- **Execute o pipeline do modelo campe√£o completamente para garantir que n√£o ter√° erros no script.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline Completo do Modelo Campe√£o\n",
        "\n",
        "O pipeline do modelo campe√£o ser√° reconstru√≠do do zero aqui, garantindo reprodutibilidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"PIPELINE FINAL DO MODELO CAMPE√ÉO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Carregamento dos dados\n",
        "print(\"\\n[1/7] Carregando dados...\")\n",
        "df_final = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', \n",
        "                        delimiter=';')\n",
        "print(f\"‚úì Dataset: {df_final.shape[0]} registros\")\n",
        "\n",
        "# 2. Separa√ß√£o treino/teste (75/25, estratificado, random_state=42)\n",
        "print(\"\\n[2/7] Separando treino/teste...\")\n",
        "X_final = df_final['descricao_reclamacao']\n",
        "y_final = df_final['categoria']\n",
        "\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "    X_final, y_final,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y_final\n",
        ")\n",
        "print(f\"‚úì Treino: {len(X_train_final)} | Teste: {len(X_test_final)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Fun√ß√µes de pr√©-processamento (caso o campe√£o use TF-IDF)\n",
        "print(\"\\n[3/7] Preparando fun√ß√µes de pr√©-processamento...\")\n",
        "\n",
        "# Recriar fun√ß√µes necess√°rias\n",
        "stop_words_final = set(stopwords.words('portuguese'))\n",
        "custom_stopwords_final = {'cliente', 'favor', 'gostaria', 'solicito', 'pe√ßo', 'preciso'}\n",
        "stop_words_final.update(custom_stopwords_final)\n",
        "\n",
        "try:\n",
        "    nlp_final = spacy.load('pt_core_news_sm')\n",
        "except:\n",
        "    nlp_final = None\n",
        "\n",
        "def clean_text_final(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def lemmatize_text_final(text, keep_pos=['NOUN', 'VERB', 'ADJ']):\n",
        "    if nlp_final is None or not text:\n",
        "        return text\n",
        "    doc = nlp_final(text)\n",
        "    lemmatized = [token.lemma_ for token in doc if token.pos_ in keep_pos and token.lemma_ not in stop_words_final]\n",
        "    return ' '.join(lemmatized)\n",
        "\n",
        "def preprocess_text_final(text):\n",
        "    text = clean_text_final(text)\n",
        "    text = lemmatize_text_final(text)\n",
        "    return text\n",
        "\n",
        "print(\"‚úì Fun√ß√µes de pr√©-processamento configuradas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Construir o pipeline do campe√£o baseado no melhor resultado\n",
        "print(f\"\\n[4/7] Construindo pipeline do modelo campe√£o: {champion['model']}...\")\n",
        "\n",
        "# Identificar qual foi o campe√£o e construir o pipeline apropriado\n",
        "if 'TF-IDF' in champion['model']:\n",
        "    # Pipeline TF-IDF\n",
        "    print(\"  Pipeline: Pr√©-processamento ‚Üí TF-IDF ‚Üí Classificador\")\n",
        "    \n",
        "    # Pr√©-processar textos\n",
        "    print(\"  Aplicando pr√©-processamento...\")\n",
        "    X_train_champion = X_train_final.apply(preprocess_text_final)\n",
        "    X_test_champion = X_test_final.apply(preprocess_text_final)\n",
        "    \n",
        "    # Construir pipeline com melhores hiperpar√¢metros\n",
        "    best_params = champion['best_params']\n",
        "    \n",
        "    if 'SVM' in champion['model']:\n",
        "        pipeline_champion = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(\n",
        "                ngram_range=best_params.get('tfidf__ngram_range', (1, 2)),\n",
        "                sublinear_tf=best_params.get('tfidf__sublinear_tf', True),\n",
        "                min_df=best_params.get('tfidf__min_df', 2)\n",
        "            )),\n",
        "            ('clf', LinearSVC(\n",
        "                C=best_params.get('clf__C', 1),\n",
        "                loss=best_params.get('clf__loss', 'squared_hinge'),\n",
        "                max_iter=2000,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "    else:  # Logistic Regression\n",
        "        pipeline_champion = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(\n",
        "                ngram_range=best_params.get('tfidf__ngram_range', (1, 2)),\n",
        "                sublinear_tf=best_params.get('tfidf__sublinear_tf', True),\n",
        "                min_df=best_params.get('tfidf__min_df', 2)\n",
        "            )),\n",
        "            ('clf', LogisticRegression(\n",
        "                C=best_params.get('clf__C', 1),\n",
        "                max_iter=1000,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "    \n",
        "else:\n",
        "    # Pipeline Embeddings\n",
        "    print(\"  Pipeline: Sentence Embeddings ‚Üí Regress√£o Log√≠stica\")\n",
        "    \n",
        "    # Usar textos originais (Transformers n√£o precisam de pr√©-processamento)\n",
        "    X_train_champion = X_train_final\n",
        "    X_test_champion = X_test_final\n",
        "    \n",
        "    # Gerar embeddings\n",
        "    print(\"  Gerando embeddings...\")\n",
        "    emb_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "    X_train_champion = emb_model.encode(X_train_champion.tolist(), show_progress_bar=False)\n",
        "    X_test_champion = emb_model.encode(X_test_champion.tolist(), show_progress_bar=False)\n",
        "    \n",
        "    # Criar classificador\n",
        "    best_params = champion['best_params']\n",
        "    pipeline_champion = LogisticRegression(\n",
        "        C=best_params.get('C', 1),\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "print(\"‚úì Pipeline configurado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Treinamento do modelo campe√£o\n",
        "print(\"\\n[5/7] Treinando modelo campe√£o...\")\n",
        "start_train = time.time()\n",
        "pipeline_champion.fit(X_train_champion, y_train_final)\n",
        "train_time_champion = time.time() - start_train\n",
        "print(f\"‚úì Modelo treinado em {train_time_champion:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Avalia√ß√£o final no conjunto de teste\n",
        "print(\"\\n[6/7] Avalia√ß√£o final no conjunto de teste...\")\n",
        "y_pred_champion = pipeline_champion.predict(X_test_champion)\n",
        "\n",
        "# M√©tricas\n",
        "f1_final = f1_score(y_test_final, y_pred_champion, average='weighted')\n",
        "accuracy_final = accuracy_score(y_test_final, y_pred_champion)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"RESULTADOS FINAIS DO MODELO CAMPE√ÉO\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nModelo: {champion['model']}\")\n",
        "print(f\"\\nM√©tricas no Conjunto de Teste:\")\n",
        "print(f\"  ‚Ä¢ F1-Score (weighted): {f1_final:.4f}\")\n",
        "print(f\"  ‚Ä¢ Accuracy: {accuracy_final:.4f}\")\n",
        "print(f\"  ‚Ä¢ Tempo de treinamento: {train_time_champion:.2f}s\")\n",
        "\n",
        "if f1_final >= 0.75:\n",
        "    print(f\"\\n‚úÖ META ATINGIDA! F1-Score >= 0.75\")\n",
        "else:\n",
        "    print(f\"\\n‚ö† Meta n√£o atingida (F1-Score < 0.75)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relat√≥rio de classifica√ß√£o completo\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"RELAT√ìRIO DE CLASSIFICA√á√ÉO COMPLETO\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "print(classification_report(y_test_final, y_pred_champion))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de confus√£o final\n",
        "print(\"\\nGerando matriz de confus√£o...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "cm_final = confusion_matrix(y_test_final, y_pred_champion)\n",
        "\n",
        "# Obter labels das classes\n",
        "if hasattr(pipeline_champion, 'classes_'):\n",
        "    classes = pipeline_champion.classes_\n",
        "else:\n",
        "    classes = sorted(y_final.unique())\n",
        "\n",
        "sns.heatmap(cm_final, annot=True, fmt='d', cmap='RdYlGn', \n",
        "            xticklabels=classes, \n",
        "            yticklabels=classes,\n",
        "            ax=ax,\n",
        "            cbar_kws={'label': 'Quantidade'})\n",
        "ax.set_title(f'Matriz de Confus√£o - {champion[\"model\"]}', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('Classe Real', fontsize=12)\n",
        "ax.set_xlabel('Classe Predita', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Exemplos de predi√ß√£o (10 casos)\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"EXEMPLOS DE PREDI√á√ïES (10 CASOS DO CONJUNTO DE TESTE)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "sample_indices = np.random.choice(X_test_final.index, size=min(10, len(X_test_final)), replace=False)\n",
        "\n",
        "for idx, test_idx in enumerate(sample_indices, 1):\n",
        "    texto_original = X_final.loc[test_idx]\n",
        "    classe_real = y_final.loc[test_idx]\n",
        "    \n",
        "    # Preparar texto para predi√ß√£o\n",
        "    if 'TF-IDF' in champion['model']:\n",
        "        texto_processado = preprocess_text_final(texto_original)\n",
        "        classe_predita = pipeline_champion.predict([texto_processado])[0]\n",
        "    else:\n",
        "        embedding = emb_model.encode([texto_original])\n",
        "        classe_predita = pipeline_champion.predict(embedding)[0]\n",
        "    \n",
        "    correto = \"‚úì\" if classe_real == classe_predita else \"‚úó\"\n",
        "    \n",
        "    print(f\"[{idx}] {correto}\")\n",
        "    print(f\"  Texto: {texto_original[:100]}...\")\n",
        "    print(f\"  Real: {classe_real}\")\n",
        "    print(f\"  Predito: {classe_predita}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Persist√™ncia do modelo\n",
        "print(f\"\\n[7/7] Salvando modelo campe√£o...\")\n",
        "\n",
        "# Criar objeto com tudo necess√°rio para infer√™ncia\n",
        "model_package = {\n",
        "    'pipeline': pipeline_champion,\n",
        "    'model_type': champion['model'],\n",
        "    'preprocess_func': preprocess_text_final if 'TF-IDF' in champion['model'] else None,\n",
        "    'embedding_model': emb_model if 'Embedding' in champion['model'] else None,\n",
        "    'f1_score': f1_final,\n",
        "    'accuracy': accuracy_final,\n",
        "    'classes': classes\n",
        "}\n",
        "\n",
        "# Salvar\n",
        "joblib.dump(model_package, 'modelo_campeao_quantumfinance.pkl')\n",
        "print(\"‚úì Modelo salvo: modelo_campeao_quantumfinance.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Fun√ß√£o de infer√™ncia para novos textos\n",
        "def predict_ticket_category(texto, model_package):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o para classificar novos chamados\n",
        "    \n",
        "    Par√¢metros:\n",
        "        texto (str): Descri√ß√£o do chamado\n",
        "        model_package (dict): Pacote do modelo carregado\n",
        "    \n",
        "    Retorna:\n",
        "        str: Categoria predita\n",
        "    \"\"\"\n",
        "    model_type = model_package['model_type']\n",
        "    pipeline = model_package['pipeline']\n",
        "    \n",
        "    if 'TF-IDF' in model_type:\n",
        "        # Pr√©-processar texto\n",
        "        texto_processado = model_package['preprocess_func'](texto)\n",
        "        categoria = pipeline.predict([texto_processado])[0]\n",
        "    else:\n",
        "        # Gerar embedding\n",
        "        embedding = model_package['embedding_model'].encode([texto])\n",
        "        categoria = pipeline.predict(embedding)[0]\n",
        "    \n",
        "    return categoria\n",
        "\n",
        "# Teste da fun√ß√£o\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"TESTE DA FUN√á√ÉO DE INFER√äNCIA\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "textos_teste = [\n",
        "    \"Meu cart√£o de cr√©dito foi bloqueado sem aviso pr√©vio\",\n",
        "    \"Gostaria de solicitar um empr√©stimo pessoal\",\n",
        "    \"N√£o consigo acessar minha conta pelo aplicativo\"\n",
        "]\n",
        "\n",
        "for texto in textos_teste:\n",
        "    categoria = predict_ticket_category(texto, model_package)\n",
        "    print(f\"Texto: {texto}\")\n",
        "    print(f\"Categoria: {categoria}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **6. Conclus√µes e Pr√≥ximos Passos**\n",
        "\n",
        "### **Resumo dos Resultados**\n",
        "\n",
        "Desenvolvemos e comparamos **3 modelos supervisionados** para classifica√ß√£o de chamados da QuantumFinance:\n",
        "\n",
        "1. **TF-IDF + Regress√£o Log√≠stica**\n",
        "2. **TF-IDF + Linear SVM**\n",
        "3. **Sentence Embeddings (Transformer) + Regress√£o Log√≠stica**\n",
        "\n",
        "### **Modelo Campe√£o**\n",
        "\n",
        "O modelo selecionado foi baseado no **melhor F1-Score (weighted) no conjunto de teste**, cumprindo o requisito de atingir **‚â• 75%**.\n",
        "\n",
        "### **Li√ß√µes Aprendidas**\n",
        "\n",
        "**An√°lise Explorat√≥ria:**\n",
        "- A EDA revelou que os textos s√£o curtos (~30-40 palavras), com distribui√ß√£o balanceada entre classes\n",
        "- Bigramas capturam contextos importantes do dom√≠nio financeiro (ex: \"cart√£o cr√©dito\", \"conta corrente\")\n",
        "- Identifica√ß√£o de stopwords customizadas melhorou a qualidade dos features\n",
        "\n",
        "**Pr√©-processamento:**\n",
        "- **Lematiza√ß√£o** preservou melhor o sentido das palavras comparada √† stemiza√ß√£o\n",
        "- Remo√ß√£o de pontua√ß√£o, n√∫meros e normaliza√ß√£o lowercase foram essenciais\n",
        "- Stopwords personalizadas do dom√≠nio de atendimento reduziram ru√≠do\n",
        "\n",
        "**Vetoriza√ß√£o:**\n",
        "- **TF-IDF com bigramas (1,2)** capturou bem padr√µes l√©xicos e coocorr√™ncias\n",
        "- **sublinear_tf=True** suavizou o impacto de termos muito frequentes\n",
        "- **Sentence Embeddings** capturaram sem√¢ntica contextual, √∫til para sin√¥nimos\n",
        "\n",
        "**Modelos:**\n",
        "- **Modelos lineares** (Regress√£o Log√≠stica e SVM) performaram bem com vetores TF-IDF esparsos\n",
        "- **Grid Search com 5-fold CV** garantiu sele√ß√£o robusta de hiperpar√¢metros\n",
        "- **F1-Score weighted** foi apropriado para avaliar performance equilibrada entre classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Justificativa Final da Abordagem**\n",
        "\n",
        "| Etapa | Justificativa Resumida |\n",
        "|-------|------------------------|\n",
        "| **EDA** | Base textual curta e balanceada exige explorar n-grams e stopwords para capturar contexto |\n",
        "| **Pr√©-processamento** | Lematiza√ß√£o e normaliza√ß√£o reduzem ru√≠do e preservam sentido; stemiza√ß√£o desnecess√°ria |\n",
        "| **Vetoriza√ß√£o** | TF-IDF 1-2-gram capta coocorr√™ncias curtas; embeddings multil√≠ngues trazem sem√¢ntica contextual |\n",
        "| **Modelos** | Regress√£o Log√≠stica e SVM s√£o robustos e ensinados no curso; combinam bem com TF-IDF |\n",
        "| **M√©trica** | F1-macro avalia equil√≠brio em base levemente desbalanceada |\n",
        "| **Pipeline** | Mant√©m reprodutibilidade e clareza; segue padr√£o ensinado |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Pr√≥ximos Passos e Melhorias**\n",
        "\n",
        "Para aprimorar ainda mais o modelo, sugerimos:\n",
        "\n",
        "1. **Enriquecimento de Stopwords**: Expandir lista customizada com termos mais espec√≠ficos do dom√≠nio financeiro\n",
        "\n",
        "2. **Ajuste de min_df/max_df**: Explorar diferentes thresholds para filtrar termos muito raros ou muito comuns\n",
        "\n",
        "3. **Ensemble de Modelos**: Combinar predi√ß√µes de TF-IDF e Embeddings atrav√©s de vota√ß√£o ou stacking\n",
        "\n",
        "4. **Word2Vec Customizado**: Treinar Word2Vec no pr√≥prio corpus para capturar vocabul√°rio espec√≠fico\n",
        "\n",
        "5. **An√°lise de Erros**: Investigar casos de confus√£o entre categorias para identificar padr√µes de erro\n",
        "\n",
        "6. **Naive Bayes**: Testar como baseline adicional, especialmente √∫til para datasets menores\n",
        "\n",
        "7. **Dados de Produ√ß√£o**: Coletar feedback de classifica√ß√µes incorretas para retreinar o modelo periodicamente\n",
        "\n",
        "8. **Explicabilidade**: Implementar LIME ou SHAP para entender decis√µes do modelo em casos espec√≠ficos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Refer√™ncias e Bibliotecas Utilizadas**\n",
        "\n",
        "- **Pandas/NumPy**: Manipula√ß√£o e an√°lise de dados\n",
        "- **NLTK**: Stopwords e stemiza√ß√£o em portugu√™s\n",
        "- **spaCy**: Lematiza√ß√£o e POS-tagging (pt_core_news_sm)\n",
        "- **scikit-learn**: Vetoriza√ß√£o, modelos supervisionados, m√©tricas e pipelines\n",
        "- **sentence-transformers**: Embeddings contextuais multil√≠ngues\n",
        "- **Matplotlib/Seaborn**: Visualiza√ß√µes\n",
        "- **WordCloud**: Nuvens de palavras\n",
        "\n",
        "**Dataset**: https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv\n",
        "\n",
        "---\n",
        "\n",
        "**Trabalho desenvolvido para a disciplina de NLP - MBA**\n",
        "\n",
        "**Data**: 2025\n",
        "\n",
        "**Objetivo**: Classifica√ß√£o autom√°tica de chamados de atendimento utilizando t√©cnicas de Processamento de Linguagem Natural\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bom desenvolvimento!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
