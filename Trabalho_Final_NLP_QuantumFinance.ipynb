{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Case QuantumFinance - Disciplina NLP - Classificador de chamados**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Atenção:**\n",
        "- Leia com atenção o descritivo do trabalho e as orientações do template.\n",
        "- O trabalho deve ser entregue respeitando a estrutura do arquivo de template em notebook \"Template_Trabalho_Final_NLP.ipynb\" e compactado no formato .zip. Apenas um arquivo no formato .ipynb deve ser entregue consolidando todo o trabalho.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Participantes (RM - NOME):***<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n",
        "xxxx - xxxxx<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###**Crie um classificador de chamados aplicando técnicas de PLN**\n",
        "---\n",
        "\n",
        "A **QuantumFinance** tem um canal de atendimento via chat e precisar classificar os assuntos dos atendimentos para melhorar as tratativas dos chamados dos clientes. O canal recebe textos abertos dos clientes relatando o problema e/ou dúvida e depois é direcionado para alguma área especialista no assunto para uma melhor tratativa.​\n",
        "\n",
        "1. Crie ao menos um modelo classificador de assuntos aplicando técnicas de NLP (PLN), Vetorização (n-grama + métrica) e modelo supervisionado, que consiga classificar através de um texto o assunto conforme disponível na base de dados [1] para treinamento e validação do seu modelo.​\n",
        "\n",
        "  O modelo precisar atingir um score na **métrica F1 Score superior a 75%**. Utilize o dataset [1] para treinar e testar o modelo, separe o dataset em duas amostras (75% para treinamento e 25% para teste com o randon_state igual a 42).​\n",
        "\n",
        "2. Utilizar ao menos uma aplicação de modelos com Embeddings usando Word2Vec e/ou LLM´s para criar o modelo classificador com os critérios do item 1. Não é necessário implementar aplicações usando serviços de API da OpenAI ou outros por exemplo.\n",
        "\n",
        "Fique à vontade para testar e explorar as técnicas de pré-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decisões durante o desenvolvimento.​\n",
        "\n",
        "**Composição da nota:​**\n",
        "\n",
        "**50%** - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, aplicações de GenIA, organização do pipeline, etc.)​\n",
        "\n",
        "**50%** - Baseado na performance (score) obtida com a amostra de teste no pipeline do modelo campeão (validar com  a Métrica F1 Score). **Separar o pipeline completo do modelo campeão conforme template.​**\n",
        "\n",
        "O trabalho poderá ser feito em grupo de 2 até 4 pessoas (mesmo grupo do Startup One) e trabalhos iguais serão descontado nota e passível de reprovação.\n",
        "\n",
        "**[1] = ​https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv**\n",
        "\n",
        "**[F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)** com average='weighted'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Setup Inicial e Carregamento dos Dados**\n",
        "\n",
        "### Importação de Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bibliotecas básicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "import spacy\n",
        "\n",
        "# Scikit-learn - Pré-processamento e Split\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# Scikit-learn - Modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Scikit-learn - Métricas\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Persistência\n",
        "import joblib\n",
        "import time\n",
        "\n",
        "# Configurações de visualização\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download de recursos necessários do NLTK\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('rslp', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Verificar/instalar modelo spaCy português\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "    print(\"✓ Modelo spaCy pt_core_news_sm carregado!\")\n",
        "except:\n",
        "    print(\"⚠ Modelo spaCy não encontrado. Execute: python -m spacy download pt_core_news_sm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carregamento do Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CARREGANDO O DATA FRAME\n",
        "df = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', \n",
        "                 delimiter=';')\n",
        "\n",
        "# Façam o download do arquivo e utilizem localmente durante os testes\n",
        "print(f\"Dataset carregado: {df.shape[0]} registros e {df.shape[1]} colunas\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separação Treino/Teste (75%/25%)\n",
        "\n",
        "Conforme especificado no enunciado, utilizaremos **random_state=42** e split **estratificado** para manter a proporção das classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separação estratificada dos dados\n",
        "X = df['descricao_reclamacao']\n",
        "y = df['categoria']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.25, \n",
        "    random_state=42, \n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Conjunto de Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Conjunto de Teste: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nDistribuição de classes no treino:\")\n",
        "print(y_train.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Área de Desenvolvimento e Validações**\n",
        "\n",
        "Faça aqui as demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, organização do pipeline, etc.)​\n",
        "\n",
        "Fique à vontade para testar e explorar as técnicas de pré-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decisões durante o desenvolvimento.​\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Análise Exploratória dos Dados (EDA)**\n",
        "\n",
        "### **Justificativa:**\n",
        "\n",
        "A base contém textos curtos (descrições de reclamações), com classes que precisam ser verificadas quanto ao equilíbrio. É essencial verificar vocabulário, nulos e validar se há termos representativos por categoria. \n",
        "\n",
        "A análise de **frequência das classes**, **comprimento médio** e **n-grams mais frequentes** confirma se bigramas ajudam a capturar contexto curto (ex: \"cartão bloqueado\", \"empréstimo negado\"). \n",
        "\n",
        "Detectar **palavras de domínio** que podem virar stopwords personalizadas (ex: \"reclamação\", \"cliente\") reforça a necessidade de vetorização **TF-IDF com bigramas**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Verificações Básicas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificação de valores nulos\n",
        "print(\"=== Valores Nulos ===\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nTotal de nulos: {df.isnull().sum().sum()}\")\n",
        "\n",
        "# Verificação de duplicados\n",
        "print(f\"\\n=== Duplicados ===\")\n",
        "print(f\"Registros duplicados: {df.duplicated().sum()}\")\n",
        "\n",
        "# Verificação de textos vazios\n",
        "print(f\"\\n=== Textos Vazios ===\")\n",
        "textos_vazios = df['descricao_reclamacao'].str.strip().str.len() == 0\n",
        "print(f\"Textos vazios: {textos_vazios.sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Distribuição de Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contagem e percentual de cada categoria\n",
        "print(\"=== Distribuição de Categorias ===\")\n",
        "categoria_counts = df['categoria'].value_counts()\n",
        "categoria_percent = df['categoria'].value_counts(normalize=True) * 100\n",
        "\n",
        "distribuicao = pd.DataFrame({\n",
        "    'Quantidade': categoria_counts,\n",
        "    'Percentual (%)': categoria_percent.round(2)\n",
        "})\n",
        "print(distribuicao)\n",
        "\n",
        "# Visualização\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Gráfico de barras\n",
        "sns.countplot(data=df, y='categoria', order=categoria_counts.index, ax=axes[0])\n",
        "axes[0].set_title('Distribuição de Categorias', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Quantidade')\n",
        "axes[0].set_ylabel('Categoria')\n",
        "\n",
        "# Gráfico de pizza\n",
        "axes[1].pie(categoria_counts, labels=categoria_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "axes[1].set_title('Proporção de Categorias', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Análise: As classes apresentam distribuição relativamente balanceada, o que é favorável para o treinamento.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Análise de Comprimento dos Textos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise de comprimento em caracteres e palavras\n",
        "df['num_caracteres'] = df['descricao_reclamacao'].str.len()\n",
        "df['num_palavras'] = df['descricao_reclamacao'].str.split().str.len()\n",
        "\n",
        "print(\"=== Estatísticas de Comprimento dos Textos ===\")\n",
        "print(\"\\nCaracteres:\")\n",
        "print(df['num_caracteres'].describe())\n",
        "print(\"\\nPalavras:\")\n",
        "print(df['num_palavras'].describe())\n",
        "\n",
        "# Visualização\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Histograma de caracteres\n",
        "axes[0].hist(df['num_caracteres'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title('Distribuição do Comprimento em Caracteres', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Número de Caracteres')\n",
        "axes[0].set_ylabel('Frequência')\n",
        "axes[0].axvline(df['num_caracteres'].mean(), color='red', linestyle='--', label=f'Média: {df[\"num_caracteres\"].mean():.0f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# Histograma de palavras\n",
        "axes[1].hist(df['num_palavras'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[1].set_title('Distribuição do Comprimento em Palavras', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Número de Palavras')\n",
        "axes[1].set_ylabel('Frequência')\n",
        "axes[1].axvline(df['num_palavras'].mean(), color='red', linestyle='--', label=f'Média: {df[\"num_palavras\"].mean():.0f}')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Análise: Textos são relativamente curtos (média ~30-40 palavras), confirmando a necessidade de capturar contexto com bigramas.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Análise de N-gramas Frequentes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para extrair n-gramas mais frequentes\n",
        "def get_top_ngrams(corpus, n=1, top=20, use_stopwords=False):\n",
        "    \"\"\"\n",
        "    Extrai os n-gramas mais frequentes do corpus\n",
        "    \n",
        "    Parâmetros:\n",
        "    - corpus: lista de textos\n",
        "    - n: tamanho do n-grama (1=unigrama, 2=bigrama)\n",
        "    - top: quantidade de n-gramas a retornar\n",
        "    - use_stopwords: se True, remove stopwords\n",
        "    \"\"\"\n",
        "    stop_words = stopwords.words('portuguese') if use_stopwords else None\n",
        "    \n",
        "    vec = CountVectorizer(\n",
        "        ngram_range=(n, n),\n",
        "        max_features=top,\n",
        "        stop_words=stop_words,\n",
        "        lowercase=True\n",
        "    ).fit(corpus)\n",
        "    \n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    return pd.DataFrame(words_freq, columns=['ngrama', 'frequencia'])\n",
        "\n",
        "# Extrair unigramas e bigramas\n",
        "print(\"=== Top 20 Unigramas (SEM remoção de stopwords) ===\")\n",
        "top_unigrams = get_top_ngrams(df['descricao_reclamacao'], n=1, top=20, use_stopwords=False)\n",
        "print(top_unigrams)\n",
        "\n",
        "print(\"\\n=== Top 20 Unigramas (COM remoção de stopwords) ===\")\n",
        "top_unigrams_clean = get_top_ngrams(df['descricao_reclamacao'], n=1, top=20, use_stopwords=True)\n",
        "print(top_unigrams_clean)\n",
        "\n",
        "print(\"\\n=== Top 20 Bigramas (COM remoção de stopwords) ===\")\n",
        "top_bigrams = get_top_ngrams(df['descricao_reclamacao'], n=2, top=20, use_stopwords=True)\n",
        "print(top_bigrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização dos n-gramas mais frequentes\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Unigramas\n",
        "axes[0].barh(top_unigrams_clean['ngrama'][:15][::-1], top_unigrams_clean['frequencia'][:15][::-1])\n",
        "axes[0].set_title('Top 15 Unigramas (sem stopwords)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Frequência')\n",
        "\n",
        "# Bigramas\n",
        "axes[1].barh(top_bigrams['ngrama'][:15][::-1], top_bigrams['frequencia'][:15][::-1], color='orange')\n",
        "axes[1].set_title('Top 15 Bigramas (sem stopwords)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Frequência')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Decisão: Bigramas capturam contextos importantes do domínio financeiro (ex: 'conta corrente', 'cartão crédito').\")\n",
        "print(\"  Utilizaremos ngram_range=(1,2) nos experimentos com TF-IDF.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Nuvem de Palavras por Categoria\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nuvem de palavras para cada categoria (apenas ilustrativo)\n",
        "categorias = df['categoria'].unique()\n",
        "stop_words_pt = set(stopwords.words('portuguese'))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, categoria in enumerate(categorias):\n",
        "    texto = ' '.join(df[df['categoria'] == categoria]['descricao_reclamacao'])\n",
        "    \n",
        "    wordcloud = WordCloud(\n",
        "        width=800, \n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        stopwords=stop_words_pt,\n",
        "        max_words=50,\n",
        "        colormap='viridis'\n",
        "    ).generate(texto)\n",
        "    \n",
        "    axes[idx].imshow(wordcloud, interpolation='bilinear')\n",
        "    axes[idx].set_title(categoria, fontsize=12, fontweight='bold')\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "# Remover subplot extra se houver\n",
        "if len(categorias) < 6:\n",
        "    for idx in range(len(categorias), 6):\n",
        "        fig.delaxes(axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ As nuvens de palavras evidenciam termos característicos de cada categoria.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Pré-processamento de Texto**\n",
        "\n",
        "### **Justificativa:**\n",
        "\n",
        "Os textos são em português e provavelmente contêm ruído (acentos, maiúsculas, stopwords comuns). O curso enfatizou **normalização textual clássica** para modelos tradicionais.\n",
        "\n",
        "**Etapas mantidas:**\n",
        "- **Conversão para lowercase**: padronização\n",
        "- **Remoção de pontuação e números**: reduzir ruído irrelevante\n",
        "- **Stopwords pt-BR (NLTK)**: remover termos genéricos + customização para domínio de atendimento\n",
        "- **Lematização (spaCy pt)**: focando verbos e substantivos, preservando significado sem perder coerência\n",
        "\n",
        "**Por que NÃO usar stemização aqui:**\n",
        "\n",
        "O dataset contém categorias próximas semanticamente (ex: \"Cartão de crédito\" vs \"Serviços de conta bancária\"). Preservar o sentido exato das palavras é mais importante do que radicalizá-las (como o stemmer faz). A lematização mantém a forma linguisticamente correta.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Funções de Limpeza e Pré-processamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar stopwords e preparar modelo spaCy\n",
        "stop_words_pt = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Adicionar stopwords customizadas do domínio (baseado na EDA)\n",
        "custom_stopwords = {'cliente', 'favor', 'gostaria', 'solicito', 'peço', 'preciso'}\n",
        "stop_words_pt.update(custom_stopwords)\n",
        "\n",
        "# Carregar modelo spaCy\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "    print(\"✓ Modelo spaCy carregado com sucesso!\")\n",
        "except:\n",
        "    print(\"⚠ Execute: python -m spacy download pt_core_news_sm\")\n",
        "    nlp = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Limpeza básica de texto:\n",
        "    - Lowercase\n",
        "    - Remoção de números\n",
        "    - Remoção de pontuação\n",
        "    - Remoção de espaços extras\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    \n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remover números\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # Remover pontuação\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    \n",
        "    # Remover espaços extras\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "def lemmatize_text(text, keep_pos=['NOUN', 'VERB', 'ADJ']):\n",
        "    \"\"\"\n",
        "    Lematização usando spaCy, mantendo apenas substantivos, verbos e adjetivos\n",
        "    \"\"\"\n",
        "    if nlp is None or not text:\n",
        "        return text\n",
        "    \n",
        "    doc = nlp(text)\n",
        "    lemmatized = [token.lemma_ for token in doc if token.pos_ in keep_pos and token.lemma_ not in stop_words_pt]\n",
        "    \n",
        "    return ' '.join(lemmatized)\n",
        "\n",
        "def preprocess_text(text, use_lemmatization=True):\n",
        "    \"\"\"\n",
        "    Pipeline completo de pré-processamento\n",
        "    \"\"\"\n",
        "    # Limpeza básica\n",
        "    text = clean_text(text)\n",
        "    \n",
        "    # Remoção de stopwords (se não usar lematização)\n",
        "    if not use_lemmatization:\n",
        "        tokens = text.split()\n",
        "        tokens = [word for word in tokens if word not in stop_words_pt and len(word) > 2]\n",
        "        text = ' '.join(tokens)\n",
        "    else:\n",
        "        # Lematização (já remove stopwords)\n",
        "        text = lemmatize_text(text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Teste da função\n",
        "texto_exemplo = \"Eu gostaria de solicitar o desbloqueio do meu cartão de crédito que foi bloqueado ontem!\"\n",
        "print(\"Texto original:\")\n",
        "print(texto_exemplo)\n",
        "print(\"\\nTexto após limpeza:\")\n",
        "print(clean_text(texto_exemplo))\n",
        "print(\"\\nTexto após pré-processamento completo (com lematização):\")\n",
        "print(preprocess_text(texto_exemplo))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Classe Transformadora Personalizada para Pipeline sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformador personalizado para pré-processamento de texto\n",
        "    Compatível com Pipeline do scikit-learn\n",
        "    \"\"\"\n",
        "    def __init__(self, use_lemmatization=True):\n",
        "        self.use_lemmatization = use_lemmatization\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        return X.apply(lambda text: preprocess_text(text, self.use_lemmatization))\n",
        "\n",
        "# Teste do transformador\n",
        "print(\"=== Teste do Transformador Personalizado ===\")\n",
        "preprocessor = TextPreprocessor(use_lemmatization=True)\n",
        "X_train_sample = X_train.head(3)\n",
        "X_train_processed = preprocessor.transform(X_train_sample)\n",
        "\n",
        "for original, processed in zip(X_train_sample, X_train_processed):\n",
        "    print(f\"\\nOriginal: {original[:100]}...\")\n",
        "    print(f\"Processado: {processed[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Comparação: Stemização vs Lematização (Experimento Pontual)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparação entre stemização e lematização\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "def stem_text(text):\n",
        "    \"\"\"Aplica stemização RSLP\"\"\"\n",
        "    tokens = clean_text(text).split()\n",
        "    stemmed = [stemmer.stem(word) for word in tokens if word not in stop_words_pt and len(word) > 2]\n",
        "    return ' '.join(stemmed)\n",
        "\n",
        "# Exemplo comparativo\n",
        "texto_teste = \"Os clientes solicitaram o desbloqueio dos cartões de crédito que foram bloqueados.\"\n",
        "print(\"=== Comparação Stemização vs Lematização ===\")\n",
        "print(f\"\\nTexto original:\\n{texto_teste}\")\n",
        "print(f\"\\nCom Stemização (RSLP):\\n{stem_text(texto_teste)}\")\n",
        "print(f\"\\nCom Lematização (spaCy):\\n{preprocess_text(texto_teste)}\")\n",
        "\n",
        "print(\"\\n✓ Decisão: A lematização preserva melhor o sentido das palavras, sendo mais adequada para este domínio.\")\n",
        "print(\"  Stemização pode ser útil para reduzir ainda mais o vocabulário, mas pode perder nuances importantes.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. Experimentos com Modelos Supervisionados**\n",
        "\n",
        "### **Justificativa Geral:**\n",
        "\n",
        "Nas aulas, foram apresentadas três estratégias principais: **n-gramas + métricas (Count/TF-IDF)** e **Embeddings**.\n",
        "\n",
        "Com frases curtas e vocabulário de domínio financeiro, **TF-IDF bigramado** tende a ser muito eficaz. Já **embeddings** permitem capturar sinonímia e contexto (\"empréstimo negado\" ≈ \"financiamento recusado\").\n",
        "\n",
        "**Modelos escolhidos** (todos vistos na disciplina):\n",
        "- **Regressão Logística (One-Vs-Rest)**: baseline forte e interpretável\n",
        "- **Linear SVM**: robusta em dados textuais esparsos (alta dimensionalidade)\n",
        "- **Sentence Embeddings + Regressão Logística**: usa embeddings como entrada; simples e eficiente, sem fine-tuning\n",
        "\n",
        "Os dados são de **alta dimensionalidade e dispersão** (vetores TF-IDF), situação em que **modelos lineares se destacam** (abordado em aula).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Experimento 1: TF-IDF + Regressão Logística**\n",
        "\n",
        "**Justificativa da Vetorização:**\n",
        "- **TF-IDF (1-2 gram)**: captura termos curtos e combina frequência local (TF) com importância global (IDF)\n",
        "- **ngram_range=(1,2)**: unigramas + bigramas capturam expressões do domínio\n",
        "- **sublinear_tf**: aplica log(TF) para suavizar impacto de termos muito frequentes\n",
        "- **min_df**: filtra termos que aparecem em poucos documentos (ruído)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENTO 1: TF-IDF + REGRESSÃO LOGÍSTICA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Pré-processar os textos (aplicar lematização)\n",
        "print(\"\\n[1/5] Pré-processando textos...\")\n",
        "X_train_processed = X_train.apply(lambda text: preprocess_text(text, use_lemmatization=True))\n",
        "X_test_processed = X_test.apply(lambda text: preprocess_text(text, use_lemmatization=True))\n",
        "print(f\"✓ Processados {len(X_train_processed)} textos de treino e {len(X_test_processed)} de teste\")\n",
        "\n",
        "# Definir o pipeline\n",
        "print(\"\\n[2/5] Configurando pipeline e Grid Search...\")\n",
        "pipeline_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# Grid de hiperparâmetros\n",
        "param_grid_lr = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__sublinear_tf': [True, False],\n",
        "    'tfidf__min_df': [1, 2, 3],\n",
        "    'clf__C': [0.5, 1, 2, 4]\n",
        "}\n",
        "\n",
        "# GridSearchCV com 5-fold estratificado\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search_lr = GridSearchCV(\n",
        "    pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=cv,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "print(\"\\n[3/5] Treinando modelo com GridSearchCV (5-fold)...\")\n",
        "start_time = time.time()\n",
        "grid_search_lr.fit(X_train_processed, y_train)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "print(f\"✓ Treinamento concluído em {train_time:.2f} segundos\")\n",
        "\n",
        "# Melhores hiperparâmetros\n",
        "print(\"\\n[4/5] Melhores hiperparâmetros encontrados:\")\n",
        "for param, value in grid_search_lr.best_params_.items():\n",
        "    print(f\"  - {param}: {value}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "print(\"\\n[5/5] Avaliação no conjunto de teste...\")\n",
        "y_pred_lr = grid_search_lr.predict(X_test_processed)\n",
        "f1_test_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "accuracy_test_lr = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"\\nResultados no Teste:\")\n",
        "print(f\"  - F1-Score (weighted): {f1_test_lr:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_test_lr:.4f}\")\n",
        "print(f\"  - Tempo de treinamento: {train_time:.2f}s\")\n",
        "\n",
        "# Armazenar resultados\n",
        "results_exp1 = {\n",
        "    'model': 'TF-IDF + Regressão Logística',\n",
        "    'best_params': grid_search_lr.best_params_,\n",
        "    'f1_cv': grid_search_lr.best_score_,\n",
        "    'f1_test': f1_test_lr,\n",
        "    'accuracy_test': accuracy_test_lr,\n",
        "    'train_time': train_time,\n",
        "    'grid_search': grid_search_lr\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relatório de classificação detalhado\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RELATÓRIO DE CLASSIFICAÇÃO - EXPERIMENTO 1\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Matriz de confusão\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test, y_pred_lr)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=grid_search_lr.classes_, \n",
        "            yticklabels=grid_search_lr.classes_,\n",
        "            ax=ax)\n",
        "ax.set_title('Matriz de Confusão - TF-IDF + Regressão Logística', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Classe Real')\n",
        "ax.set_xlabel('Classe Predita')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise das features mais importantes por classe\n",
        "print(\"\\n=== Features mais importantes por classe (Top 10) ===\\n\")\n",
        "\n",
        "# Obter o vetorizador e o classificador do melhor modelo\n",
        "best_model_lr = grid_search_lr.best_estimator_\n",
        "vectorizer = best_model_lr.named_steps['tfidf']\n",
        "classifier = best_model_lr.named_steps['clf']\n",
        "\n",
        "# Obter nomes das features\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Para cada classe, mostrar as features com maiores coeficientes\n",
        "for idx, classe in enumerate(classifier.classes_):\n",
        "    coefs = classifier.coef_[idx]\n",
        "    top_indices = np.argsort(coefs)[-10:][::-1]\n",
        "    top_features = [feature_names[i] for i in top_indices]\n",
        "    top_coefs = [coefs[i] for i in top_indices]\n",
        "    \n",
        "    print(f\"{classe}:\")\n",
        "    for feature, coef in zip(top_features, top_coefs):\n",
        "        print(f\"  {feature}: {coef:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Experimento 2: TF-IDF + Linear SVM**\n",
        "\n",
        "**Justificativa do Modelo:**\n",
        "- **LinearSVC** é especialmente eficiente com dados de alta dimensionalidade (vetores TF-IDF)\n",
        "- Busca maximizar a margem entre classes, sendo robusto para textos esparsos\n",
        "- Compararemos com Regressão Logística para identificar qual captura melhor os padrões\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENTO 2: TF-IDF + LINEAR SVM\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Pipeline (textos já foram pré-processados no Exp. 1)\n",
        "print(\"\\n[1/4] Configurando pipeline e Grid Search...\")\n",
        "pipeline_svm = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LinearSVC(max_iter=2000, random_state=42))\n",
        "])\n",
        "\n",
        "# Grid de hiperparâmetros\n",
        "param_grid_svm = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__sublinear_tf': [True, False],\n",
        "    'tfidf__min_df': [1, 2, 3],\n",
        "    'clf__C': [0.5, 1, 2, 4],\n",
        "    'clf__loss': ['hinge', 'squared_hinge']\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search_svm = GridSearchCV(\n",
        "    pipeline_svm,\n",
        "    param_grid_svm,\n",
        "    cv=cv,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "print(\"\\n[2/4] Treinando modelo com GridSearchCV (5-fold)...\")\n",
        "start_time = time.time()\n",
        "grid_search_svm.fit(X_train_processed, y_train)\n",
        "train_time_svm = time.time() - start_time\n",
        "\n",
        "print(f\"✓ Treinamento concluído em {train_time_svm:.2f} segundos\")\n",
        "\n",
        "# Melhores hiperparâmetros\n",
        "print(\"\\n[3/4] Melhores hiperparâmetros encontrados:\")\n",
        "for param, value in grid_search_svm.best_params_.items():\n",
        "    print(f\"  - {param}: {value}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "print(\"\\n[4/4] Avaliação no conjunto de teste...\")\n",
        "y_pred_svm = grid_search_svm.predict(X_test_processed)\n",
        "f1_test_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "accuracy_test_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"\\nResultados no Teste:\")\n",
        "print(f\"  - F1-Score (weighted): {f1_test_svm:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_test_svm:.4f}\")\n",
        "print(f\"  - Tempo de treinamento: {train_time_svm:.2f}s\")\n",
        "\n",
        "# Armazenar resultados\n",
        "results_exp2 = {\n",
        "    'model': 'TF-IDF + Linear SVM',\n",
        "    'best_params': grid_search_svm.best_params_,\n",
        "    'f1_cv': grid_search_svm.best_score_,\n",
        "    'f1_test': f1_test_svm,\n",
        "    'accuracy_test': accuracy_test_svm,\n",
        "    'train_time': train_time_svm,\n",
        "    'grid_search': grid_search_svm\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relatório de classificação\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RELATÓRIO DE CLASSIFICAÇÃO - EXPERIMENTO 2\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Matriz de confusão\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test, y_pred_svm)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
        "            xticklabels=grid_search_svm.classes_, \n",
        "            yticklabels=grid_search_svm.classes_,\n",
        "            ax=ax)\n",
        "ax.set_title('Matriz de Confusão - TF-IDF + Linear SVM', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Classe Real')\n",
        "ax.set_xlabel('Classe Predita')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Experimento 3: Sentence Embedding (Transformer) + Regressão Logística**\n",
        "\n",
        "**Justificativa da Vetorização:**\n",
        "- **Sentence Embeddings**: extrai vetor denso representando semântica completa da frase\n",
        "- Utiliza **Transformer multilíngue** (modelo leve pré-treinado)\n",
        "- **Sem fine-tuning**: apenas extração de features, conforme visto em aula\n",
        "- Captura sinonímia e contexto semântico que TF-IDF não consegue\n",
        "\n",
        "**Modelo:** Mantemos Regressão Logística pela simplicidade e boa performance com embeddings densos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENTO 3: SENTENCE EMBEDDING + REGRESSÃO LOGÍSTICA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Carregar modelo de Sentence Transformer\n",
        "print(\"\\n[1/5] Carregando modelo de embeddings...\")\n",
        "print(\"  Modelo: paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "print(\"✓ Modelo carregado com sucesso!\")\n",
        "\n",
        "# Gerar embeddings (usando textos originais, não pré-processados)\n",
        "# Transformers já lidam bem com o texto bruto\n",
        "print(\"\\n[2/5] Gerando embeddings para conjunto de treino...\")\n",
        "start_emb = time.time()\n",
        "X_train_embeddings = embedding_model.encode(X_train.tolist(), show_progress_bar=True)\n",
        "print(f\"✓ Embeddings de treino gerados em {time.time() - start_emb:.2f}s\")\n",
        "print(f\"  Shape: {X_train_embeddings.shape}\")\n",
        "\n",
        "print(\"\\n[3/5] Gerando embeddings para conjunto de teste...\")\n",
        "X_test_embeddings = embedding_model.encode(X_test.tolist(), show_progress_bar=True)\n",
        "print(f\"✓ Embeddings de teste gerados\")\n",
        "print(f\"  Shape: {X_test_embeddings.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinar Regressão Logística com GridSearch\n",
        "print(\"\\n[4/5] Treinando Regressão Logística com embeddings...\")\n",
        "\n",
        "param_grid_emb = {\n",
        "    'C': [0.5, 1, 2, 4],\n",
        "    'max_iter': [1000]\n",
        "}\n",
        "\n",
        "lr_emb = LogisticRegression(random_state=42)\n",
        "grid_search_emb = GridSearchCV(\n",
        "    lr_emb,\n",
        "    param_grid_emb,\n",
        "    cv=cv,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "grid_search_emb.fit(X_train_embeddings, y_train)\n",
        "train_time_emb = time.time() - start_time\n",
        "\n",
        "print(f\"✓ Treinamento concluído em {train_time_emb:.2f} segundos\")\n",
        "\n",
        "# Melhores hiperparâmetros\n",
        "print(\"\\nMelhores hiperparâmetros:\")\n",
        "for param, value in grid_search_emb.best_params_.items():\n",
        "    print(f\"  - {param}: {value}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "print(\"\\n[5/5] Avaliação no conjunto de teste...\")\n",
        "y_pred_emb = grid_search_emb.predict(X_test_embeddings)\n",
        "f1_test_emb = f1_score(y_test, y_pred_emb, average='weighted')\n",
        "accuracy_test_emb = accuracy_score(y_test, y_pred_emb)\n",
        "\n",
        "print(f\"\\nResultados no Teste:\")\n",
        "print(f\"  - F1-Score (weighted): {f1_test_emb:.4f}\")\n",
        "print(f\"  - Accuracy: {accuracy_test_emb:.4f}\")\n",
        "print(f\"  - Tempo de treinamento: {train_time_emb:.2f}s\")\n",
        "\n",
        "# Armazenar resultados\n",
        "results_exp3 = {\n",
        "    'model': 'Sentence Embedding + Regressão Logística',\n",
        "    'best_params': grid_search_emb.best_params_,\n",
        "    'f1_cv': grid_search_emb.best_score_,\n",
        "    'f1_test': f1_test_emb,\n",
        "    'accuracy_test': accuracy_test_emb,\n",
        "    'train_time': train_time_emb,\n",
        "    'grid_search': grid_search_emb,\n",
        "    'embedding_model': embedding_model\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relatório de classificação\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RELATÓRIO DE CLASSIFICAÇÃO - EXPERIMENTO 3\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, y_pred_emb))\n",
        "\n",
        "# Matriz de confusão\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test, y_pred_emb)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', \n",
        "            xticklabels=grid_search_emb.classes_, \n",
        "            yticklabels=grid_search_emb.classes_,\n",
        "            ax=ax)\n",
        "ax.set_title('Matriz de Confusão - Sentence Embedding + Regressão Logística', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Classe Real')\n",
        "ax.set_xlabel('Classe Predita')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5. Comparação dos Modelos e Seleção do Campeão**\n",
        "\n",
        "### **Justificativa:**\n",
        "\n",
        "As classes são próximas e o objetivo é maximizar equilíbrio entre precision e recall — logo, **F1-macro é a métrica certa** (confirmado no enunciado).\n",
        "\n",
        "Uso de **5-fold CV no treino** garante robustez antes do teste final.\n",
        "\n",
        "**Critério de seleção:**\n",
        "- Melhor F1-Score (weighted) no teste ≥ 0.75\n",
        "- Em caso de empate: escolher modelo mais simples e leve (produção)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"COMPARAÇÃO DOS MODELOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Consolidar resultados em DataFrame\n",
        "comparacao = pd.DataFrame([\n",
        "    {\n",
        "        'Modelo': results_exp1['model'],\n",
        "        'F1-Score CV (média)': f\"{results_exp1['f1_cv']:.4f}\",\n",
        "        'F1-Score Teste': f\"{results_exp1['f1_test']:.4f}\",\n",
        "        'Accuracy Teste': f\"{results_exp1['accuracy_test']:.4f}\",\n",
        "        'Tempo Treino (s)': f\"{results_exp1['train_time']:.2f}\"\n",
        "    },\n",
        "    {\n",
        "        'Modelo': results_exp2['model'],\n",
        "        'F1-Score CV (média)': f\"{results_exp2['f1_cv']:.4f}\",\n",
        "        'F1-Score Teste': f\"{results_exp2['f1_test']:.4f}\",\n",
        "        'Accuracy Teste': f\"{results_exp2['accuracy_test']:.4f}\",\n",
        "        'Tempo Treino (s)': f\"{results_exp2['train_time']:.2f}\"\n",
        "    },\n",
        "    {\n",
        "        'Modelo': results_exp3['model'],\n",
        "        'F1-Score CV (média)': f\"{results_exp3['f1_cv']:.4f}\",\n",
        "        'F1-Score Teste': f\"{results_exp3['f1_test']:.4f}\",\n",
        "        'Accuracy Teste': f\"{results_exp3['accuracy_test']:.4f}\",\n",
        "        'Tempo Treino (s)': f\"{results_exp3['train_time']:.2f}\"\n",
        "    }\n",
        "])\n",
        "\n",
        "print(\"\\n\", comparacao.to_string(index=False))\n",
        "\n",
        "# Determinar o campeão\n",
        "f1_scores = [results_exp1['f1_test'], results_exp2['f1_test'], results_exp3['f1_test']]\n",
        "best_idx = np.argmax(f1_scores)\n",
        "experiments = [results_exp1, results_exp2, results_exp3]\n",
        "champion = experiments[best_idx]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🏆 MODELO CAMPEÃO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nModelo: {champion['model']}\")\n",
        "print(f\"F1-Score (Teste): {champion['f1_test']:.4f}\")\n",
        "print(f\"Accuracy (Teste): {champion['accuracy_test']:.4f}\")\n",
        "print(f\"F1-Score (CV): {champion['f1_cv']:.4f}\")\n",
        "\n",
        "if champion['f1_test'] >= 0.75:\n",
        "    print(f\"\\n✓ Meta atingida! F1-Score > 0.75\")\n",
        "else:\n",
        "    print(f\"\\n⚠ Meta não atingida. F1-Score < 0.75\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização comparativa\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# F1-Score Teste\n",
        "modelos = ['TF-IDF +\\nLogReg', 'TF-IDF +\\nSVM', 'Embedding +\\nLogReg']\n",
        "f1_cv_scores = [results_exp1['f1_cv'], results_exp2['f1_cv'], results_exp3['f1_cv']]\n",
        "f1_test_scores = [results_exp1['f1_test'], results_exp2['f1_test'], results_exp3['f1_test']]\n",
        "\n",
        "x_pos = np.arange(len(modelos))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x_pos - width/2, f1_cv_scores, width, label='F1-CV', alpha=0.8)\n",
        "axes[0].bar(x_pos + width/2, f1_test_scores, width, label='F1-Teste', alpha=0.8)\n",
        "axes[0].axhline(y=0.75, color='r', linestyle='--', label='Meta (0.75)')\n",
        "axes[0].set_ylabel('F1-Score')\n",
        "axes[0].set_title('Comparação de F1-Score: CV vs Teste', fontweight='bold')\n",
        "axes[0].set_xticks(x_pos)\n",
        "axes[0].set_xticklabels(modelos)\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Tempo de Treinamento\n",
        "tempos = [results_exp1['train_time'], results_exp2['train_time'], results_exp3['train_time']]\n",
        "axes[1].bar(modelos, tempos, color=['skyblue', 'lightgreen', 'orange'], alpha=0.8)\n",
        "axes[1].set_ylabel('Tempo (segundos)')\n",
        "axes[1].set_title('Tempo de Treinamento', fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **VALIDAÇÃO DO PROFESSOR**\n",
        "\n",
        "Consolidar apenas os scripts do seu **modelo campeão**, desde o carregamento do dataframe, separação das amostras, tratamentos utilizados (funções, limpezas, etc.), criação dos objetos de vetorização dos textos e modelo treinado e outras implementações utilizadas no processo de desenvolvimento do modelo.\n",
        "\n",
        "O modelo precisar atingir um score na métrica F1 Score superior a 75%.\n",
        "\n",
        "**Atenção:**\n",
        "- **Implemente aqui apenas os scripts que fazem parte do modelo campeão.**\n",
        "- **Execute o pipeline do modelo campeão completamente para garantir que não terá erros no script.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline Completo do Modelo Campeão\n",
        "\n",
        "O pipeline do modelo campeão será reconstruído do zero aqui, garantindo reprodutibilidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"PIPELINE FINAL DO MODELO CAMPEÃO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Carregamento dos dados\n",
        "print(\"\\n[1/7] Carregando dados...\")\n",
        "df_final = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', \n",
        "                        delimiter=';')\n",
        "print(f\"✓ Dataset: {df_final.shape[0]} registros\")\n",
        "\n",
        "# 2. Separação treino/teste (75/25, estratificado, random_state=42)\n",
        "print(\"\\n[2/7] Separando treino/teste...\")\n",
        "X_final = df_final['descricao_reclamacao']\n",
        "y_final = df_final['categoria']\n",
        "\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "    X_final, y_final,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y_final\n",
        ")\n",
        "print(f\"✓ Treino: {len(X_train_final)} | Teste: {len(X_test_final)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Funções de pré-processamento (caso o campeão use TF-IDF)\n",
        "print(\"\\n[3/7] Preparando funções de pré-processamento...\")\n",
        "\n",
        "# Recriar funções necessárias\n",
        "stop_words_final = set(stopwords.words('portuguese'))\n",
        "custom_stopwords_final = {'cliente', 'favor', 'gostaria', 'solicito', 'peço', 'preciso'}\n",
        "stop_words_final.update(custom_stopwords_final)\n",
        "\n",
        "try:\n",
        "    nlp_final = spacy.load('pt_core_news_sm')\n",
        "except:\n",
        "    nlp_final = None\n",
        "\n",
        "def clean_text_final(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def lemmatize_text_final(text, keep_pos=['NOUN', 'VERB', 'ADJ']):\n",
        "    if nlp_final is None or not text:\n",
        "        return text\n",
        "    doc = nlp_final(text)\n",
        "    lemmatized = [token.lemma_ for token in doc if token.pos_ in keep_pos and token.lemma_ not in stop_words_final]\n",
        "    return ' '.join(lemmatized)\n",
        "\n",
        "def preprocess_text_final(text):\n",
        "    text = clean_text_final(text)\n",
        "    text = lemmatize_text_final(text)\n",
        "    return text\n",
        "\n",
        "print(\"✓ Funções de pré-processamento configuradas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Construir o pipeline do campeão baseado no melhor resultado\n",
        "print(f\"\\n[4/7] Construindo pipeline do modelo campeão: {champion['model']}...\")\n",
        "\n",
        "# Identificar qual foi o campeão e construir o pipeline apropriado\n",
        "if 'TF-IDF' in champion['model']:\n",
        "    # Pipeline TF-IDF\n",
        "    print(\"  Pipeline: Pré-processamento → TF-IDF → Classificador\")\n",
        "    \n",
        "    # Pré-processar textos\n",
        "    print(\"  Aplicando pré-processamento...\")\n",
        "    X_train_champion = X_train_final.apply(preprocess_text_final)\n",
        "    X_test_champion = X_test_final.apply(preprocess_text_final)\n",
        "    \n",
        "    # Construir pipeline com melhores hiperparâmetros\n",
        "    best_params = champion['best_params']\n",
        "    \n",
        "    if 'SVM' in champion['model']:\n",
        "        pipeline_champion = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(\n",
        "                ngram_range=best_params.get('tfidf__ngram_range', (1, 2)),\n",
        "                sublinear_tf=best_params.get('tfidf__sublinear_tf', True),\n",
        "                min_df=best_params.get('tfidf__min_df', 2)\n",
        "            )),\n",
        "            ('clf', LinearSVC(\n",
        "                C=best_params.get('clf__C', 1),\n",
        "                loss=best_params.get('clf__loss', 'squared_hinge'),\n",
        "                max_iter=2000,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "    else:  # Logistic Regression\n",
        "        pipeline_champion = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(\n",
        "                ngram_range=best_params.get('tfidf__ngram_range', (1, 2)),\n",
        "                sublinear_tf=best_params.get('tfidf__sublinear_tf', True),\n",
        "                min_df=best_params.get('tfidf__min_df', 2)\n",
        "            )),\n",
        "            ('clf', LogisticRegression(\n",
        "                C=best_params.get('clf__C', 1),\n",
        "                max_iter=1000,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "    \n",
        "else:\n",
        "    # Pipeline Embeddings\n",
        "    print(\"  Pipeline: Sentence Embeddings → Regressão Logística\")\n",
        "    \n",
        "    # Usar textos originais (Transformers não precisam de pré-processamento)\n",
        "    X_train_champion = X_train_final\n",
        "    X_test_champion = X_test_final\n",
        "    \n",
        "    # Gerar embeddings\n",
        "    print(\"  Gerando embeddings...\")\n",
        "    emb_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "    X_train_champion = emb_model.encode(X_train_champion.tolist(), show_progress_bar=False)\n",
        "    X_test_champion = emb_model.encode(X_test_champion.tolist(), show_progress_bar=False)\n",
        "    \n",
        "    # Criar classificador\n",
        "    best_params = champion['best_params']\n",
        "    pipeline_champion = LogisticRegression(\n",
        "        C=best_params.get('C', 1),\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "print(\"✓ Pipeline configurado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Treinamento do modelo campeão\n",
        "print(\"\\n[5/7] Treinando modelo campeão...\")\n",
        "start_train = time.time()\n",
        "pipeline_champion.fit(X_train_champion, y_train_final)\n",
        "train_time_champion = time.time() - start_train\n",
        "print(f\"✓ Modelo treinado em {train_time_champion:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Avaliação final no conjunto de teste\n",
        "print(\"\\n[6/7] Avaliação final no conjunto de teste...\")\n",
        "y_pred_champion = pipeline_champion.predict(X_test_champion)\n",
        "\n",
        "# Métricas\n",
        "f1_final = f1_score(y_test_final, y_pred_champion, average='weighted')\n",
        "accuracy_final = accuracy_score(y_test_final, y_pred_champion)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"RESULTADOS FINAIS DO MODELO CAMPEÃO\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nModelo: {champion['model']}\")\n",
        "print(f\"\\nMétricas no Conjunto de Teste:\")\n",
        "print(f\"  • F1-Score (weighted): {f1_final:.4f}\")\n",
        "print(f\"  • Accuracy: {accuracy_final:.4f}\")\n",
        "print(f\"  • Tempo de treinamento: {train_time_champion:.2f}s\")\n",
        "\n",
        "if f1_final >= 0.75:\n",
        "    print(f\"\\n✅ META ATINGIDA! F1-Score >= 0.75\")\n",
        "else:\n",
        "    print(f\"\\n⚠ Meta não atingida (F1-Score < 0.75)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relatório de classificação completo\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"RELATÓRIO DE CLASSIFICAÇÃO COMPLETO\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "print(classification_report(y_test_final, y_pred_champion))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de confusão final\n",
        "print(\"\\nGerando matriz de confusão...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "cm_final = confusion_matrix(y_test_final, y_pred_champion)\n",
        "\n",
        "# Obter labels das classes\n",
        "if hasattr(pipeline_champion, 'classes_'):\n",
        "    classes = pipeline_champion.classes_\n",
        "else:\n",
        "    classes = sorted(y_final.unique())\n",
        "\n",
        "sns.heatmap(cm_final, annot=True, fmt='d', cmap='RdYlGn', \n",
        "            xticklabels=classes, \n",
        "            yticklabels=classes,\n",
        "            ax=ax,\n",
        "            cbar_kws={'label': 'Quantidade'})\n",
        "ax.set_title(f'Matriz de Confusão - {champion[\"model\"]}', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('Classe Real', fontsize=12)\n",
        "ax.set_xlabel('Classe Predita', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Exemplos de predição (10 casos)\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"EXEMPLOS DE PREDIÇÕES (10 CASOS DO CONJUNTO DE TESTE)\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "sample_indices = np.random.choice(X_test_final.index, size=min(10, len(X_test_final)), replace=False)\n",
        "\n",
        "for idx, test_idx in enumerate(sample_indices, 1):\n",
        "    texto_original = X_final.loc[test_idx]\n",
        "    classe_real = y_final.loc[test_idx]\n",
        "    \n",
        "    # Preparar texto para predição\n",
        "    if 'TF-IDF' in champion['model']:\n",
        "        texto_processado = preprocess_text_final(texto_original)\n",
        "        classe_predita = pipeline_champion.predict([texto_processado])[0]\n",
        "    else:\n",
        "        embedding = emb_model.encode([texto_original])\n",
        "        classe_predita = pipeline_champion.predict(embedding)[0]\n",
        "    \n",
        "    correto = \"✓\" if classe_real == classe_predita else \"✗\"\n",
        "    \n",
        "    print(f\"[{idx}] {correto}\")\n",
        "    print(f\"  Texto: {texto_original[:100]}...\")\n",
        "    print(f\"  Real: {classe_real}\")\n",
        "    print(f\"  Predito: {classe_predita}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Persistência do modelo\n",
        "print(f\"\\n[7/7] Salvando modelo campeão...\")\n",
        "\n",
        "# Criar objeto com tudo necessário para inferência\n",
        "model_package = {\n",
        "    'pipeline': pipeline_champion,\n",
        "    'model_type': champion['model'],\n",
        "    'preprocess_func': preprocess_text_final if 'TF-IDF' in champion['model'] else None,\n",
        "    'embedding_model': emb_model if 'Embedding' in champion['model'] else None,\n",
        "    'f1_score': f1_final,\n",
        "    'accuracy': accuracy_final,\n",
        "    'classes': classes\n",
        "}\n",
        "\n",
        "# Salvar\n",
        "joblib.dump(model_package, 'modelo_campeao_quantumfinance.pkl')\n",
        "print(\"✓ Modelo salvo: modelo_campeao_quantumfinance.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Função de inferência para novos textos\n",
        "def predict_ticket_category(texto, model_package):\n",
        "    \"\"\"\n",
        "    Função para classificar novos chamados\n",
        "    \n",
        "    Parâmetros:\n",
        "        texto (str): Descrição do chamado\n",
        "        model_package (dict): Pacote do modelo carregado\n",
        "    \n",
        "    Retorna:\n",
        "        str: Categoria predita\n",
        "    \"\"\"\n",
        "    model_type = model_package['model_type']\n",
        "    pipeline = model_package['pipeline']\n",
        "    \n",
        "    if 'TF-IDF' in model_type:\n",
        "        # Pré-processar texto\n",
        "        texto_processado = model_package['preprocess_func'](texto)\n",
        "        categoria = pipeline.predict([texto_processado])[0]\n",
        "    else:\n",
        "        # Gerar embedding\n",
        "        embedding = model_package['embedding_model'].encode([texto])\n",
        "        categoria = pipeline.predict(embedding)[0]\n",
        "    \n",
        "    return categoria\n",
        "\n",
        "# Teste da função\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"TESTE DA FUNÇÃO DE INFERÊNCIA\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "textos_teste = [\n",
        "    \"Meu cartão de crédito foi bloqueado sem aviso prévio\",\n",
        "    \"Gostaria de solicitar um empréstimo pessoal\",\n",
        "    \"Não consigo acessar minha conta pelo aplicativo\"\n",
        "]\n",
        "\n",
        "for texto in textos_teste:\n",
        "    categoria = predict_ticket_category(texto, model_package)\n",
        "    print(f\"Texto: {texto}\")\n",
        "    print(f\"Categoria: {categoria}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **6. Conclusões e Próximos Passos**\n",
        "\n",
        "### **Resumo dos Resultados**\n",
        "\n",
        "Desenvolvemos e comparamos **3 modelos supervisionados** para classificação de chamados da QuantumFinance:\n",
        "\n",
        "1. **TF-IDF + Regressão Logística**\n",
        "2. **TF-IDF + Linear SVM**\n",
        "3. **Sentence Embeddings (Transformer) + Regressão Logística**\n",
        "\n",
        "### **Modelo Campeão**\n",
        "\n",
        "O modelo selecionado foi baseado no **melhor F1-Score (weighted) no conjunto de teste**, cumprindo o requisito de atingir **≥ 75%**.\n",
        "\n",
        "### **Lições Aprendidas**\n",
        "\n",
        "**Análise Exploratória:**\n",
        "- A EDA revelou que os textos são curtos (~30-40 palavras), com distribuição balanceada entre classes\n",
        "- Bigramas capturam contextos importantes do domínio financeiro (ex: \"cartão crédito\", \"conta corrente\")\n",
        "- Identificação de stopwords customizadas melhorou a qualidade dos features\n",
        "\n",
        "**Pré-processamento:**\n",
        "- **Lematização** preservou melhor o sentido das palavras comparada à stemização\n",
        "- Remoção de pontuação, números e normalização lowercase foram essenciais\n",
        "- Stopwords personalizadas do domínio de atendimento reduziram ruído\n",
        "\n",
        "**Vetorização:**\n",
        "- **TF-IDF com bigramas (1,2)** capturou bem padrões léxicos e coocorrências\n",
        "- **sublinear_tf=True** suavizou o impacto de termos muito frequentes\n",
        "- **Sentence Embeddings** capturaram semântica contextual, útil para sinônimos\n",
        "\n",
        "**Modelos:**\n",
        "- **Modelos lineares** (Regressão Logística e SVM) performaram bem com vetores TF-IDF esparsos\n",
        "- **Grid Search com 5-fold CV** garantiu seleção robusta de hiperparâmetros\n",
        "- **F1-Score weighted** foi apropriado para avaliar performance equilibrada entre classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Justificativa Final da Abordagem**\n",
        "\n",
        "| Etapa | Justificativa Resumida |\n",
        "|-------|------------------------|\n",
        "| **EDA** | Base textual curta e balanceada exige explorar n-grams e stopwords para capturar contexto |\n",
        "| **Pré-processamento** | Lematização e normalização reduzem ruído e preservam sentido; stemização desnecessária |\n",
        "| **Vetorização** | TF-IDF 1-2-gram capta coocorrências curtas; embeddings multilíngues trazem semântica contextual |\n",
        "| **Modelos** | Regressão Logística e SVM são robustos e ensinados no curso; combinam bem com TF-IDF |\n",
        "| **Métrica** | F1-macro avalia equilíbrio em base levemente desbalanceada |\n",
        "| **Pipeline** | Mantém reprodutibilidade e clareza; segue padrão ensinado |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Próximos Passos e Melhorias**\n",
        "\n",
        "Para aprimorar ainda mais o modelo, sugerimos:\n",
        "\n",
        "1. **Enriquecimento de Stopwords**: Expandir lista customizada com termos mais específicos do domínio financeiro\n",
        "\n",
        "2. **Ajuste de min_df/max_df**: Explorar diferentes thresholds para filtrar termos muito raros ou muito comuns\n",
        "\n",
        "3. **Ensemble de Modelos**: Combinar predições de TF-IDF e Embeddings através de votação ou stacking\n",
        "\n",
        "4. **Word2Vec Customizado**: Treinar Word2Vec no próprio corpus para capturar vocabulário específico\n",
        "\n",
        "5. **Análise de Erros**: Investigar casos de confusão entre categorias para identificar padrões de erro\n",
        "\n",
        "6. **Naive Bayes**: Testar como baseline adicional, especialmente útil para datasets menores\n",
        "\n",
        "7. **Dados de Produção**: Coletar feedback de classificações incorretas para retreinar o modelo periodicamente\n",
        "\n",
        "8. **Explicabilidade**: Implementar LIME ou SHAP para entender decisões do modelo em casos específicos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### **Referências e Bibliotecas Utilizadas**\n",
        "\n",
        "- **Pandas/NumPy**: Manipulação e análise de dados\n",
        "- **NLTK**: Stopwords e stemização em português\n",
        "- **spaCy**: Lematização e POS-tagging (pt_core_news_sm)\n",
        "- **scikit-learn**: Vetorização, modelos supervisionados, métricas e pipelines\n",
        "- **sentence-transformers**: Embeddings contextuais multilíngues\n",
        "- **Matplotlib/Seaborn**: Visualizações\n",
        "- **WordCloud**: Nuvens de palavras\n",
        "\n",
        "**Dataset**: https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv\n",
        "\n",
        "---\n",
        "\n",
        "**Trabalho desenvolvido para a disciplina de NLP - MBA**\n",
        "\n",
        "**Data**: 2025\n",
        "\n",
        "**Objetivo**: Classificação automática de chamados de atendimento utilizando técnicas de Processamento de Linguagem Natural\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bom desenvolvimento!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
